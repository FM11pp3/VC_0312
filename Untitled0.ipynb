{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FM11pp3/VC_0312/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Configuration"
      ],
      "metadata": {
        "id": "mMcWN_uBb3SE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Dhl6jjwBncCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv"
      ],
      "metadata": {
        "id": "Dg5Fq8LLklSu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define GPU"
      ],
      "metadata": {
        "id": "1woZGMS4pvUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Execution Device\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "!nvidia-smi\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zSJ2Vkfl-5f",
        "outputId": "46afc67d-22dc-4d96-d8a9-ff3e4c27e813"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeds"
      ],
      "metadata": {
        "id": "B7c-Epgvnfhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # if you use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False # Recommended for reproducibility\n",
        "\n",
        "# --- Example of how to use it in your synthetic image generation cell ---\n",
        "# Choose a fixed seed value\n",
        "FIXED_SEED = 42\n",
        "\n",
        "print(f\"Setting all random seeds to {FIXED_SEED} for reproducibility...\")\n",
        "set_all_seeds(FIXED_SEED)\n",
        "print(\"✔️ Seeds set.\")\n",
        "\n",
        "# Now, when you generate noise for the cGAN, it will be reproducible:\n",
        "# For example, in your synthetic image generation loop:\n",
        "# noise = torch.randn(num_to_generate, z_dim, 1, 1, device=DEVICE)\n",
        "\n",
        "# If you run the above code, the 'noise' tensor will be identical every time if the seed is fixed."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqdSr5rLnUoL",
        "outputId": "cb3f5378-953f-4702-99d0-6f05df7f2d73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting all random seeds to 42 for reproducibility...\n",
            "✔️ Seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data *Dataset, pth models and results"
      ],
      "metadata": {
        "id": "GTrLC6bSnjCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "3d_LSbVbnyV9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e61875b",
        "outputId": "0b84898d-973b-4436-ce15-7df68b82ee85"
      },
      "source": [
        "# Ensure dataset is present\n",
        "data_root_dir = Path(\"/content/InfraredSolarModules\")\n",
        "if not data_root_dir.exists() or not any(data_root_dir.iterdir()):\n",
        "    print(\"Downloading and extracting dataset...\")\n",
        "    !rm -rf /content/*\n",
        "    !wget -q -O /content/infrared.zip \\\n",
        "      \"https://github.com/RaptorMaps/InfraredSolarModules/raw/master/2020-02-14_InfraredSolarModules.zip\"\n",
        "    !unzip -q /content/infrared.zip -d /content/\n",
        "    print(\"Dataset downloaded and extracted.\")\n",
        "else:\n",
        "    print(\"Dataset already present, skipping download and extraction.\")\n",
        "\n",
        "data_dir = Path(\"/content/InfraredSolarModules\")\n",
        "meta_path = data_dir / \"module_metadata.json\"\n",
        "with open(meta_path, \"r\") as f:\n",
        "    metadata = json.load(f)\n",
        "print(\"✔️ Metadata loaded:\", len(metadata), \"imagens\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and extracting dataset...\n",
            "Dataset downloaded and extracted.\n",
            "✔️ Metadata loaded: 20000 imagens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Create DataFrame with 'path' and class mappings ---\n",
        "all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "\n",
        "rows = []\n",
        "for img_id, info in metadata.items():\n",
        "    full_image_path = data_dir / info[\"image_filepath\"]\n",
        "    # Store original class name as 'class_name' and map to numerical 'label'\n",
        "    rows.append({\"img_id\": img_id, \"class_name\": info[\"anomaly_class\"], \"path\": str(full_image_path)})\n",
        "df = pd.DataFrame(rows)\n",
        "df['label'] = df['class_name'].map(classes_map)\n",
        "\n",
        "print(\"✔️ DataFrame created with 'path', 'class_name', and 'label' columns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR_rhUwk4bJF",
        "outputId": "fe13582b-ddac-4757-9470-eb99b6e8b77a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ DataFrame created with 'path', 'class_name', and 'label' columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone the models I built"
      ],
      "metadata": {
        "id": "VB3zXRAmyiiB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d18a0e05",
        "outputId": "5ce0242b-760d-479a-b57e-f309b637c663"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configurações para Clonagem de Leitura ---\n",
        "# Estas são as informações do seu repositório, que são públicas\n",
        "GITHUB_USERNAME = globals().get('GITHUB_USERNAME', 'FM11pp3') # Seu GitHub username\n",
        "REPO_FOLDER = globals().get('REPO_FOLDER', 'VC_0312')        # Nome do seu repositório\n",
        "\n",
        "# Caminho onde o repositório será clonado\n",
        "repo_path_read_only = Path(f\"/content/{REPO_FOLDER}\")\n",
        "\n",
        "# URL pública HTTPS para clonagem de leitura\n",
        "public_repo_url = f\"https://github.com/{GITHUB_USERNAME}/{REPO_FOLDER}.git\"\n",
        "\n",
        "# --- Operação de Clonagem ---\n",
        "if not repo_path_read_only.exists():\n",
        "    print(f\"Clonando repositório '{REPO_FOLDER}' para acesso de leitura em {repo_path_read_only}...\")\n",
        "    %cd /content/\n",
        "    !git clone {public_repo_url}\n",
        "    print(f\"✔️ Repositório '{REPO_FOLDER}' clonado com sucesso para acesso de leitura.\")\n",
        "else:\n",
        "    print(f\"Repositório '{REPO_FOLDER}' já existe em {repo_path_read_only}, ignorando clonagem.\")\n",
        "    print(\"Se precisar de uma versão atualizada, pode remover o diretório e executar novamente esta célula.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonando repositório 'VC_0312' para acesso de leitura em /content/VC_0312...\n",
            "/content\n",
            "Cloning into 'VC_0312'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 72 (delta 5), reused 67 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (72/72), 14.49 MiB | 39.77 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "✔️ Repositório 'VC_0312' clonado com sucesso para acesso de leitura.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 -> Exploratory Analysis"
      ],
      "metadata": {
        "id": "KipfC9qK4ILp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unbalanced Dataset:\n",
        "\n",
        "* Como relatado no artigo, os dados estão unbalanced é preciso *balancear* -< Vamos usar um RandomWeight Sampler (explicar o que é) e GAN para gerar imagens"
      ],
      "metadata": {
        "id": "0_w_8kPD4iHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate class distribution\n",
        "class_counts = df['label'].value_counts().sort_index()\n",
        "\n",
        "# Plotting the class distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')\n",
        "plt.title('Distribuição de Classes no Dataset Original')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Número de Amostras')\n",
        "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Distribuição de Classes:\\n\", class_counts)"
      ],
      "metadata": {
        "id": "aaXqmdL84MuV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "c19fa201-fe91-49bd-ed77-e414e4f3f028"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-831758874.py:9: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuição de Classes:\n",
            " label\n",
            "0      1877\n",
            "1      1288\n",
            "2       940\n",
            "3      1499\n",
            "4       175\n",
            "5       249\n",
            "6       246\n",
            "7     10000\n",
            "8       827\n",
            "9      1056\n",
            "10      204\n",
            "11     1639\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at the images"
      ],
      "metadata": {
        "id": "TcLOo8j-52tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Visualizing 5 random sample images...\")\n",
        "# Get unique image filenames to avoid duplicates if any\n",
        "# The 'image_filepath' is stored in the 'path' column of the DataFrame\n",
        "unique_images = df['path'].unique()\n",
        "\n",
        "# Randomly select 5 image file paths\n",
        "sample_image_paths = np.random.choice(unique_images, size=5, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, img_filepath_relative in enumerate(sample_image_paths):\n",
        "    # Construct full image path\n",
        "    # The full path is already in the 'path' column\n",
        "    full_img_path = Path(img_filepath_relative)\n",
        "\n",
        "    # Load image using OpenCV\n",
        "    img = cv.imread(str(full_img_path))\n",
        "\n",
        "    if img is not None:\n",
        "        # Convert BGR to RGB for matplotlib display\n",
        "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "        # Get the anomaly class for this image\n",
        "        anomaly_class = df[df['path'] == img_filepath_relative]['label'].iloc[0]\n",
        "\n",
        "        plt.subplot(1, 5, i + 1) # 1 row, 5 columns\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title(f\"Class: {anomaly_class}\")\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        print(f\"Warning: Could not load image {full_img_path}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "4NaW6B8M5r4I",
        "outputId": "77c63016-a312-4be7-e919-f257e356f597"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizing 5 random sample images...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART A: BUILT THE BASIS"
      ],
      "metadata": {
        "id": "j60L6oKw58s1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Train and Test"
      ],
      "metadata": {
        "id": "Ma9NOeFJFsFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# VER ANEXO PARA VER COMO FOI CRIADO\n",
        "# Define paths for the training and testing data lists (these CSVs will now contain 'path', 'class_name', 'label')\n",
        "train_data_path = \"/content/VC_0312/full_train_data_list.csv\"\n",
        "test_data_path = \"/content/VC_0312/final_test_data_list.csv\"\n",
        "\n",
        "# Ensure `classes_map` is available. If not, re-run the data loading and mapping cells.\n",
        "# Assuming `classes_map` is already defined from previous cells (JR_rhUwk4bJF).\n",
        "if 'classes_map' not in globals():\n",
        "    raise RuntimeError(\"Error: `classes_map` not found. Please ensure cells defining data mappings (e.g., JR_rhUwk4bJF) are executed.\")\n",
        "\n",
        "# Load the training DataFrame\n",
        "train_df = pd.read_csv(train_data_path)\n",
        "# The 'label' column is already in the CSV, but we re-map to ensure consistency if classes_map changed\n",
        "train_df['label'] = train_df['class_name'].map(classes_map)\n",
        "\n",
        "# Load the testing DataFrame\n",
        "test_df = pd.read_csv(test_data_path)\n",
        "# The 'label' column is already in the CSV, but we re-map to ensure consistency if classes_map changed\n",
        "test_df['label'] = test_df['class_name'].map(classes_map)\n",
        "\n",
        "# Reset index for clean DataFrames\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"✔️ Training data loaded from {train_data_path} ({len(train_df)} samples).\")\n",
        "print(f\"✔️ Testing data loaded from {test_data_path} ({len(test_df)} samples).\")\n",
        "print(\"Validation split will be handled via k-fold cross-validation on the training set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c643eee2-0647-46ca-d158-2de29c4f9e6b",
        "id": "6EncxnD3Gr7q"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Training data loaded from /content/VC_0312/full_train_data_list.csv (16000 samples).\n",
            "✔️ Testing data loaded from /content/VC_0312/final_test_data_list.csv (4000 samples).\n",
            "Validation split will be handled via k-fold cross-validation on the training set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "185305af",
        "outputId": "db47328d-6c3f-4523-c174-a20102d9a685"
      },
      "source": [
        "print(\"Updated train_df head (with full image paths):\")\n",
        "display(train_df.head())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated train_df head (with full image paths):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    filename  class_name  label\n",
              "0   9145.jpg  Vegetation     11\n",
              "1   1178.jpg       Diode      3\n",
              "2  14418.jpg  No-Anomaly      7\n",
              "3  17272.jpg  No-Anomaly      7\n",
              "4   3301.jpg   Shadowing      9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cb2a9bb-63d2-4152-b89c-1fc2666c0471\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9145.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1178.jpg</td>\n",
              "      <td>Diode</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14418.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17272.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3301.jpg</td>\n",
              "      <td>Shadowing</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cb2a9bb-63d2-4152-b89c-1fc2666c0471')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cb2a9bb-63d2-4152-b89c-1fc2666c0471 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cb2a9bb-63d2-4152-b89c-1fc2666c0471');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eae26a3c-ffdf-4dfe-9194-cefd7ce2a744\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eae26a3c-ffdf-4dfe-9194-cefd7ce2a744')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eae26a3c-ffdf-4dfe-9194-cefd7ce2a744 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(train_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1178.jpg\",\n          \"3301.jpg\",\n          \"14418.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Diode\",\n          \"Shadowing\",\n          \"Vegetation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "987baea8",
        "outputId": "556b002a-8384-4951-b377-4aaa21b92bc5"
      },
      "source": [
        "print(\"\\nUpdated test_df head (with full image paths):\")\n",
        "display(test_df.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated test_df head (with full image paths):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    filename  class_name  label\n",
              "0   8857.jpg  Vegetation     11\n",
              "1   8573.jpg  Vegetation     11\n",
              "2   2303.jpg       Diode      3\n",
              "3  17675.jpg  No-Anomaly      7\n",
              "4   3989.jpg  Cell-Multi      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a505716-a092-493d-9df1-342fd63b2c50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8857.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8573.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2303.jpg</td>\n",
              "      <td>Diode</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17675.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3989.jpg</td>\n",
              "      <td>Cell-Multi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a505716-a092-493d-9df1-342fd63b2c50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a505716-a092-493d-9df1-342fd63b2c50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a505716-a092-493d-9df1-342fd63b2c50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ae9f3411-4dad-44ad-b649-a59686a53a07\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae9f3411-4dad-44ad-b649-a59686a53a07')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ae9f3411-4dad-44ad-b649-a59686a53a07 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(test_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"8573.jpg\",\n          \"3989.jpg\",\n          \"2303.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Diode\",\n          \"Cell-Multi\",\n          \"Vegetation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform"
      ],
      "metadata": {
        "id": "oYJGujJSKgNS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a03b4d2d-9873-4128-e2cc-b32267d7519e",
        "id": "j3lovn9RFwOD"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from PIL import Image # For opening image files\n",
        "\n",
        "# Assuming `train_df`, `test_df`, `all_classes` are already loaded and available from previous cells.\n",
        "# If not, please run the relevant data loading and splitting cells.\n",
        "\n",
        "# Define image transformations for the dataset\n",
        "# This transform assumes grayscale images (1 channel)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), # Resize images to 64x64\n",
        "    transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Normalize(\n",
        "        mean=(0.5,),             # Normalize for 1-channel image (grayscale)\n",
        "        std=(0.5,)\n",
        "    )\n",
        "])\n",
        "\n",
        "# Define the custom SolarDataset class (reusing the logic from Annex 2)\n",
        "class SolarDataset(data.Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"path\"]).convert(\"L\") # Open image and convert to grayscale\n",
        "        label = row[\"label\"]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Determine the number of classes (assuming `all_classes` is globally available)\n",
        "num_classes = len(all_classes)\n",
        "print(f\"Number of classes detected: {num_classes}\")\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = SolarDataset(train_df, transform=transform)\n",
        "test_dataset = SolarDataset(test_df, transform=transform)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32 # You can adjust this value\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,       # Shuffle training data\n",
        "    num_workers=2       # Number of subprocesses to use for data loading\n",
        ")\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,      # No need to shuffle test data\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"✔️ Training and Testing DataLoaders created with batch size {batch_size}.\")\n",
        "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in test_loader: {len(test_loader)}\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes detected: 12\n",
            "✔️ Training and Testing DataLoaders created with batch size 32.\n",
            "Number of batches in train_loader: 500\n",
            "Number of batches in test_loader: 125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YC7n35N7enO",
        "outputId": "8a6cc65d-58e2-4499-caec-729d34f6594d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6400 entries, 0 to 6399\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   path        6400 non-null   object\n",
            " 1   class_name  6400 non-null   object\n",
            " 2   label       6400 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 150.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balance Data"
      ],
      "metadata": {
        "id": "yEejQ4GJzFnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Prova que não é preicso geral até a maioritária:https://ieeexplore.ieee.org/document/8253599\n",
        "\n",
        "*https://pdf.sciencedirectassets.com/273474/1-s2.0-S1574954120X00021/1-s2.0-S1574954120300352/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIT%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIGjHKeHSZfOry9AOeG1Q2rR9BFeGUpJsQhmt%2FQZGKGtOAiEA7NQUCbUIlP3cDs9zLHhr6GQES2dTauLtJiwROdW33oEqsgUITRAFGgwwNTkwMDM1NDY4NjUiDKSPlj9XxfVpA2A2kiqPBYHneV63AVBSaddYKLI1%2Fzk8uK7tyRRQdw3VZ6ktoSxBGSGYvuKMf%2BgvLWrOrxtDZR1SLHWvgHP7ey%2FbGTsG2N9FoaLhbVDWPu1xyUnKb0BPQeQZeh6mwzlojar5t0dX8ac%2FbMfXMudqT6bJh66tAOsslq5sa1Y8IkstHrhQGiXLHA4KFaaYru1EbayneIthczWD4cXRYjeO%2BPhb2v0JNoLasGJAPZvxpJtuiOlY%2B0lANi8iH9n%2BPnh%2BEwUGWHACJSH2N7OH%2F6h0b0yDniwfbHMxt6ZTnEOhIy%2BDL5NwuyIgDAsgnndWFW2q%2FV807iDf3tNKibS%2Bf5Ffmxx0K2OQRdJKOZdW8Gv22fZ%2F%2BYSgT61DsglL0HRma%2FfPVPjOGEIIPMOmZ5gpR0jnitK7dKrw6b6h5ZY0WiN%2BO%2Fg1zooAGkgw%2Bgns6elzlTluk7YjvvoahAk3ZeFH8i%2FnjGNoP9f5Y7kDVW4u1RuvibdPfvhk9OOE0o6i54fIrs5DmIvsz0z2xMruryealm34UicknuLpKt6Hyyzq8eVLy%2FA5STSaiYXD0e9IEnn%2BXGHSPFBWOlzeCsJ9sPLrnXGOXUo67Bx4F6bkg7tzYy9iR53W%2F1P2R%2BTJ0DYvClMWHMz9bv%2FNiRZ8%2FYXA9ty6mokwHl5DPfG7yuu7qpxVIzXGA9LrRbf9Kxoxw88GqTqsEa165CLNy9tV4MjU3eSzoqUC2HYMC5VHJalFie0%2Fyb2uTgr6zAMP6fwoub80eWRQrafos6D6FTEeuwRSugbEyk5KNRipeCVrOLUEe8QsBNduIv0aCyeJePObKwt328pE29h%2FyVPhRQBRBgFixZ4xxOjBCPdxwPKlrA%2FXokj14sgNthmuZJ0n9DkwsMvHyQY6sQHzV1SXnIWHhQy%2BUGchJ%2FsOPVBXHGIWkZl7e0D1sspiS33rmKIwUQH%2B8i9AjBsJTB7kD0iWLuyMmxgO0F052qpcSXsKJjnmYuyun9xgp7Wu%2FYq%2FQjHowuseYMCGzAOaGqm%2F6BoKUhy%2BvytbNW%2Fb%2FDkeYF68gWfWTgnSzUpAssbM5EpdMkTAq5quvcK9N6wBb2%2F8EPcr54cIqo8qMMrfAK5E5jpc88hU7GilTf09bET8GCs%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20251204T211139Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYV3ANLIK4%2F20251204%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=9c9c332495ff7e25fcc1a678ab63bbda7ef0dcb3637d80e7ca3d8fa5624aae88&hash=8c63e36da8072e20e89edb5dfbe94cd779e1e10c5d228329220e438950b3d7de&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1574954120300352&tid=spdf-7ee80c7e-79f6-4048-bdb8-fb6e7c92c40c&sid=a9fe2efc48b2874c29397a6-b4b9655e4038gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0a12590358075b035d5056&rr=9a8e4c253f6b055d&cc=pt\n",
        "\n",
        "* Quanto gerar: https://www.diva-portal.org/smash/get/diva2:1985406/FULLTEXT01.pdf"
      ],
      "metadata": {
        "id": "24RmDq7hMACF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -> GAN Proposal\n",
        "\n",
        "* Explicar importância utilziaçõ e que aqui só está o que é preciso para resolver, toda a construção está no annex2"
      ],
      "metadata": {
        "id": "HfuTaIf-4rQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define cGAN Conditional Generator Network\n",
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, img_channels, num_classes, embed_size=100):\n",
        "        super(ConditionalGenerator, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.img_channels = img_channels\n",
        "        self.z_dim = z_dim\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.label_embedding = nn.Embedding(num_classes, embed_size)\n",
        "        self.input_dim = z_dim + embed_size\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(self.input_dim, 256, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, img_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        label_embed = self.label_embedding(labels).view(-1, self.embed_size, 1, 1)\n",
        "        input_vec = torch.cat([noise, label_embed], 1)\n",
        "        return self.main(input_vec)\n",
        "\n",
        "print(\"✔️ `ConditionalGenerator` class defined globally.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKiIgn734lxZ",
        "outputId": "cda103ee-2cdc-4e15-afb9-44636f2b8f65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ `ConditionalGenerator` class defined globally.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# VER ANEXO PARA VER COMO FOI CRIADO\n",
        "# Define paths for the training and testing data lists (these CSVs will now contain 'path', 'class_name', 'label')\n",
        "gan_path = \"/content/VC_0312/cgan_generated_outputs/cgan_generator_minority_classes.pth\""
      ],
      "metadata": {
        "id": "EJXZL6oJywqB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Sampler\n",
        "\n",
        "* Without Gan and Data augmentation\n"
      ],
      "metadata": {
        "id": "H9_j8OO3pcvt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fd97a38",
        "outputId": "5ab7cfcf-af6f-40c5-cb7a-0cb40b1675cb"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd # Ensure pandas is imported for DataFrame operations\n",
        "\n",
        "print(\"Calculating sample weights for WeightedRandomSampler...\")\n",
        "\n",
        "# 1. Get class counts from the original, imbalanced train_df\n",
        "# Ensure `train_df` is available from the previous step\n",
        "if 'train_df' not in globals():\n",
        "    raise RuntimeError(\"Error: `train_df` not found. Please ensure the previous step to load original data was executed.\")\n",
        "\n",
        "class_counts = train_df['label'].value_counts().sort_index()\n",
        "print(\"Original class counts:\", class_counts.to_dict())\n",
        "\n",
        "# 2. Calculate class frequencies (proportion of each class in the dataset)\n",
        "# Ensure all possible classes are covered, even if some have zero counts in the current train_df subset\n",
        "# Use `num_classes` from previous cells or infer it\n",
        "if 'num_classes' not in globals():\n",
        "    if 'all_classes' in globals():\n",
        "        num_classes = len(all_classes)\n",
        "    else:\n",
        "        num_classes = train_df['label'].nunique() # Fallback, but ideally from `all_classes`\n",
        "    print(f\"⚠️ `num_classes` not found, inferred as {num_classes}.\")\n",
        "\n",
        "# Create a Series with all classes and their counts, filling missing with 0\n",
        "all_class_counts = pd.Series(0, index=range(num_classes))\n",
        "all_class_counts.update(class_counts)\n",
        "\n",
        "class_frequencies = all_class_counts / len(train_df)\n",
        "# Replace 0 frequencies with a small epsilon to avoid division by zero for weights if a class is completely missing\n",
        "class_frequencies = class_frequencies.replace(0, np.finfo(float).eps)\n",
        "\n",
        "print(\"Class frequencies:\", class_frequencies.to_dict())\n",
        "\n",
        "# 3. Calculate inverse class frequencies (weights for each class)\n",
        "# The weight for a class is inversely proportional to its frequency\n",
        "class_weights = 1.0 / class_frequencies\n",
        "print(\"Class weights (inverse frequencies):\", class_weights.to_dict())\n",
        "\n",
        "# 4. Map these class weights to each sample in the train_df\n",
        "sample_weights = [class_weights[label] for label in train_df['label']]\n",
        "sample_weights = torch.DoubleTensor(sample_weights)\n",
        "\n",
        "print(\"✔️ Sample weights calculated and converted to PyTorch DoubleTensor.\")\n",
        "print(f\"First 5 sample weights: {sample_weights[:5].tolist()}\")\n",
        "print(f\"Total number of sample weights: {len(sample_weights)}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating sample weights for WeightedRandomSampler...\n",
            "Original class counts: {0: 1502, 1: 1030, 2: 752, 3: 1199, 4: 140, 5: 199, 6: 197, 7: 8000, 8: 662, 9: 845, 10: 163, 11: 1311}\n",
            "Class frequencies: {0: 0.093875, 1: 0.064375, 2: 0.047, 3: 0.0749375, 4: 0.00875, 5: 0.0124375, 6: 0.0123125, 7: 0.5, 8: 0.041375, 9: 0.0528125, 10: 0.0101875, 11: 0.0819375}\n",
            "Class weights (inverse frequencies): {0: 10.652463382157125, 1: 15.533980582524272, 2: 21.27659574468085, 3: 13.344453711426187, 4: 114.28571428571428, 5: 80.40201005025125, 6: 81.21827411167513, 7: 2.0, 8: 24.16918429003021, 9: 18.93491124260355, 10: 98.15950920245399, 11: 12.204424103737605}\n",
            "✔️ Sample weights calculated and converted to PyTorch DoubleTensor.\n",
            "First 5 sample weights: [12.204424103737605, 13.344453711426187, 2.0, 2.0, 18.93491124260355]\n",
            "Total number of sample weights: 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "b0925e3a",
        "outputId": "a2ac511b-7f5a-4eea-f7f1-c0d48d10d0d5"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Ensuring original `train_df` is loaded and ready...\")\n",
        "\n",
        "# 1. Check if `train_df` is already loaded. If not, load it.\n",
        "if 'train_df' not in globals() or not isinstance(train_df, pd.DataFrame):\n",
        "    print(\"⚠️ `train_df` not found or not a DataFrame. Attempting to load from '/content/full_train_data_list.csv'.\")\n",
        "    try:\n",
        "        train_df = pd.read_csv(\"/content/full_train_data_list.csv\")\n",
        "        print(\"✔️ `train_df` loaded from CSV.\")\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\"Error: `full_train_data_list.csv` not found. Please ensure data split has been performed.\")\n",
        "else:\n",
        "    print(\"✔️ `train_df` is already loaded.\")\n",
        "\n",
        "# 2. Ensure `classes_map` is available. If not, reload it.\n",
        "if 'classes_map' not in globals():\n",
        "    print(\"⚠️ `classes_map` not found. Attempting to reload from metadata.\")\n",
        "    data_dir = Path(\"/content/InfraredSolarModules\")\n",
        "    meta_path = data_dir / \"module_metadata.json\"\n",
        "    if not meta_path.exists():\n",
        "        raise FileNotFoundError(\"Metadata file not found. Please ensure the dataset is downloaded and extracted correctly.\")\n",
        "\n",
        "    with open(meta_path, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "    all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "    classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "    idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "    print(\"✔️ `classes_map` reloaded.\")\n",
        "else:\n",
        "    print(\"✔️ `classes_map` is already defined.\")\n",
        "\n",
        "# 3. Ensure 'label' column is numerical using `classes_map`.\n",
        "# Check if 'label' column exists and if it needs mapping.\n",
        "if 'label' not in train_df.columns or train_df['label'].dtype == 'object':\n",
        "    print(\"⚠️ 'label' column missing or not numerical. Mapping 'class_name' to 'label' using `classes_map`.\")\n",
        "    if 'class_name' in train_df.columns:\n",
        "        train_df['label'] = train_df['class_name'].map(classes_map)\n",
        "        if train_df['label'].isnull().any():\n",
        "            print(\"Warning: Some class names could not be mapped to numerical labels.\")\n",
        "    else:\n",
        "        raise ValueError(\"Error: 'class_name' column not found for mapping to numerical labels.\")\n",
        "else:\n",
        "    print(\"✔️ 'label' column is already numerical.\")\n",
        "\n",
        "print(\"Original `train_df` head (imbalanced state):\")\n",
        "display(train_df.head())\n",
        "\n",
        "print(\"Original `train_df` class distribution (imbalanced state):\")\n",
        "display(train_df['label'].value_counts().sort_index())\n",
        "\n",
        "\n",
        "# 4. Map these class weights to each sample in the train_df\n",
        "# Ensure `class_weights` from the previous cell is available\n",
        "if 'class_weights' not in globals():\n",
        "    raise RuntimeError(\"Error: `class_weights` not found. Please ensure the step to calculate sample weights (cell a04c6fe5) was executed.\")\n",
        "sample_weights = [class_weights[label] for label in train_df['label']]\n",
        "sample_weights = torch.DoubleTensor(sample_weights)\n",
        "\n",
        "print(\"✔️ Sample weights calculated and converted to PyTorch DoubleTensor.\")\n",
        "print(f\"First 5 sample weights: {sample_weights[:5].tolist()}\")\n",
        "print(f\"Total number of sample weights: {len(sample_weights)}\")\n",
        "\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "print(\"Creating SolarDataset and DataLoader with WeightedRandomSampler...\")\n",
        "\n",
        "# Ensure `transform` is available. It was defined in cell j3lovn9RFwOD and new_conditional_generator_definition.\n",
        "if 'transform' not in globals():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)), # Resize images to 64x64\n",
        "        transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "        transforms.Normalize(\n",
        "            mean=(0.5,),             # Normalize for 1-channel image (grayscale)\n",
        "            std=(0.5,)\n",
        "        )\n",
        "    ])\n",
        "    print(\"⚠️ `transform` pipeline not found, re-defined.\")\n",
        "else:\n",
        "    print(\"✔️ `transform` pipeline is already defined.\")\n",
        "\n",
        "# Ensure SolarDataset class is available (it was defined in cell j3lovn9RFwOD and new_conditional_generator_definition)\n",
        "if 'SolarDataset' not in globals():\n",
        "    class SolarDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, df, transform=None):\n",
        "            self.df = df.reset_index(drop=True)\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.df)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            row = self.df.iloc[idx]\n",
        "            image = Image.open(row[\"path\"]).convert(\"L\") # Open image and convert to grayscale\n",
        "            label = row[\"label\"]\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "    print(\"⚠️ `SolarDataset` class not found, re-defined.\")\n",
        "else:\n",
        "    print(\"✔️ `SolarDataset` class is already defined.\")\n",
        "\n",
        "# 1. Instantiate SolarDataset for the original, imbalanced training data\n",
        "train_dataset_weighted = SolarDataset(train_df, transform=transform)\n",
        "print(\"✔️ `train_dataset_weighted` created from original `train_df`.\")\n",
        "\n",
        "# 2. Instantiate WeightedRandomSampler\n",
        "# The `replacement=True` argument means samples can be drawn multiple times.\n",
        "# `num_samples` is set to the total number of samples to process in one epoch.\n",
        "weighted_sampler = torch.utils.data.WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "print(\"✔️ `WeightedRandomSampler` created.\")\n",
        "\n",
        "# 3. Define batch size and number of workers\n",
        "# `batch_size` and `num_workers` are assumed to be defined from previous cells (e.g., j3lovn9RFwOD).\n",
        "# If not, default values will be used.\n",
        "if 'batch_size' not in globals():\n",
        "    batch_size = 32\n",
        "    print(f\"⚠️ `batch_size` not found, defaulting to {batch_size}.\")\n",
        "if 'num_workers' not in globals():\n",
        "    num_workers = 2\n",
        "    print(f\"⚠️ `num_workers` not found, defaulting to {num_workers}.\")\n",
        "\n",
        "# 4. Create a DataLoader using the WeightedRandomSampler\n",
        "# IMPORTANT: When using a sampler, `shuffle` must be set to `False` as the sampler handles the shuffling.\n",
        "weighted_train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset_weighted,\n",
        "    batch_size=batch_size,\n",
        "    sampler=weighted_sampler, # Use the weighted sampler\n",
        "    shuffle=False,            # Must be False when using a sampler\n",
        "    num_workers=num_workers\n",
        ")\n",
        "print(\"✔️ `weighted_train_loader` created with `WeightedRandomSampler`.\")\n",
        "\n",
        "print(f\"Number of batches in weighted_train_loader: {len(weighted_train_loader)}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensuring original `train_df` is loaded and ready...\n",
            "✔️ `train_df` is already loaded.\n",
            "✔️ `classes_map` is already defined.\n",
            "✔️ 'label' column is already numerical.\n",
            "Original `train_df` head (imbalanced state):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    filename  class_name  label\n",
              "0   9145.jpg  Vegetation     11\n",
              "1   1178.jpg       Diode      3\n",
              "2  14418.jpg  No-Anomaly      7\n",
              "3  17272.jpg  No-Anomaly      7\n",
              "4   3301.jpg   Shadowing      9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82192756-8d37-4187-b8b2-90b4bc651382\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9145.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1178.jpg</td>\n",
              "      <td>Diode</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14418.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17272.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3301.jpg</td>\n",
              "      <td>Shadowing</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82192756-8d37-4187-b8b2-90b4bc651382')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82192756-8d37-4187-b8b2-90b4bc651382 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82192756-8d37-4187-b8b2-90b4bc651382');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-acb4ae73-a07c-4236-8ee1-d3dc2ccf9511\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acb4ae73-a07c-4236-8ee1-d3dc2ccf9511')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-acb4ae73-a07c-4236-8ee1-d3dc2ccf9511 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"Number of batches in weighted_train_loader: {len(weighted_train_loader)}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1178.jpg\",\n          \"3301.jpg\",\n          \"14418.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Diode\",\n          \"Shadowing\",\n          \"Vegetation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original `train_df` class distribution (imbalanced state):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "label\n",
              "0     1502\n",
              "1     1030\n",
              "2      752\n",
              "3     1199\n",
              "4      140\n",
              "5      199\n",
              "6      197\n",
              "7     8000\n",
              "8      662\n",
              "9      845\n",
              "10     163\n",
              "11    1311\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Sample weights calculated and converted to PyTorch DoubleTensor.\n",
            "First 5 sample weights: [12.204424103737605, 13.344453711426187, 2.0, 2.0, 18.93491124260355]\n",
            "Total number of sample weights: 16000\n",
            "Creating SolarDataset and DataLoader with WeightedRandomSampler...\n",
            "✔️ `transform` pipeline is already defined.\n",
            "✔️ `SolarDataset` class is already defined.\n",
            "✔️ `train_dataset_weighted` created from original `train_df`.\n",
            "✔️ `WeightedRandomSampler` created.\n",
            "✔️ `weighted_train_loader` created with `WeightedRandomSampler`.\n",
            "Number of batches in weighted_train_loader: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "gcdskp2yqD6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- NetworkCNN Model (adapted from Collab class 10) ---\n",
        "class NetworkCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        dummy_input = torch.randn(1, 1, 64, 64) # Batch size 1, 1 channel, 64x64\n",
        "        with torch.no_grad():\n",
        "            x = self.pool(F.relu(self.conv1(dummy_input)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            flattened_size = torch.flatten(x, 1).shape[1]\n",
        "\n",
        "        self.fc1 = nn.Linear(flattened_size, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "print(\"✔️ NetworkCNN model defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnNQRtvxp2CC",
        "outputId": "8ff02de6-5014-4363-c8ec-728459673265"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ NetworkCNN model defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K.folds"
      ],
      "metadata": {
        "id": "RCPGQdKQ4foD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Redefine DEVICE (from original notebook setup) ---\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# --- Redefine NetworkCNN Model (adapted from Collab class 10) ---\n",
        "class NetworkCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # Dynamically calculate flattened_size\n",
        "        # Use a dummy input with the expected input size for the model\n",
        "        dummy_input = torch.randn(1, 1, 64, 64) # Batch size 1, 1 channel, 64x64 image\n",
        "        with torch.no_grad():\n",
        "            x = self.pool(F.relu(self.conv1(dummy_input)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            flattened_size = torch.flatten(x, 1).shape[1]\n",
        "\n",
        "        self.fc1 = nn.Linear(flattened_size, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# --- Helper Functions Train/Validation/Test (re-defined) ---\n",
        "def saveModel(model: nn.Module, path: str):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    # print(f\"Modelo guardado em: {path}\") # Suppress verbose output during k-fold\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, loss_fn, optimizer, device,\n",
        "          num_epochs, path_model, problem_type=\"multiclass\", verbatim=False):\n",
        "    model.to(device)\n",
        "    best_val_acc = -1 # Keep track of best validation accuracy\n",
        "    best_epoch = -1\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_acc  = 0.0\n",
        "\n",
        "        for images, labels in train_dataloader:\n",
        "            images = images.to(device)\n",
        "            if problem_type == \"binary\":\n",
        "                labels = labels.float().unsqueeze(1).to(device)\n",
        "            else:\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if problem_type == \"binary\":\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).float()\n",
        "                acc = (preds == labels).float().mean().item()\n",
        "            else:\n",
        "                preds = outputs.argmax(1)\n",
        "                acc = (preds == labels).float().mean().item()\n",
        "\n",
        "            running_acc += acc\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_dataloader)\n",
        "        epoch_train_acc  = running_acc  / len(train_dataloader)\n",
        "\n",
        "        # --- Validation after each epoch ---\n",
        "        epoch_val_loss, epoch_val_acc = validate(model, val_dataloader, loss_fn, device, problem_type=problem_type)\n",
        "\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_accuracies.append(epoch_train_acc)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        val_accuracies.append(epoch_val_acc)\n",
        "\n",
        "        if epoch_val_acc > best_val_acc:\n",
        "            saveModel(model, path_model)\n",
        "            best_val_acc = epoch_val_acc\n",
        "            best_epoch = epoch\n",
        "\n",
        "            if verbatim:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss={epoch_train_loss:.4f} | Train Acc={epoch_train_acc:.4f} | Val Loss={epoch_val_loss:.4f} | Val Acc={epoch_val_acc:.4f} (Best)\")\n",
        "        elif verbatim:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss={epoch_train_loss:.4f} | Train Acc={epoch_train_acc:.4f} | Val Loss={epoch_val_loss:.4f} | Val Acc={epoch_val_acc:.4f}\")\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies, best_val_acc, best_epoch\n",
        "\n",
        "def validate(model, dataloader, loss_fn, device, problem_type=\"multiclass\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    running_loss = 0.0\n",
        "    running_acc  = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            if problem_type == \"binary\":\n",
        "                labels = labels.float().unsqueeze(1).to(device)\n",
        "            else:\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if problem_type == \"binary\":\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).float()\n",
        "                acc = (preds == labels).float().mean().item()\n",
        "            else:\n",
        "                preds = outputs.argmax(1)\n",
        "                acc = (preds == labels).float().mean().item()\n",
        "\n",
        "            running_acc += acc\n",
        "\n",
        "    val_loss = running_loss / len(dataloader)\n",
        "    val_acc  = running_acc  / len(dataloader)\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def test(model, dataloader, loss_fn, device, problem_type=\"multiclass\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_preds  = []\n",
        "    all_labels = []\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            if problem_type == \"binary\":\n",
        "                labels_in = labels.float().unsqueeze(1).to(device)\n",
        "            else:\n",
        "                labels_in = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels_in)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if problem_type == \"binary\":\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).float().cpu().numpy().flatten()\n",
        "            else:\n",
        "                preds = outputs.argmax(1).cpu().numpy()\n",
        "\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_loss = running_loss / len(dataloader)\n",
        "    return test_loss, all_preds, all_labels\n",
        "\n",
        "def get_predictions(model, dataloader, device, problem_type=\"multiclass\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_probs = []\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            if problem_type == \"multiclass\":\n",
        "                probs = torch.softmax(outputs, dim=1)\n",
        "                preds = torch.argmax(probs, dim=1)\n",
        "                all_probs.append(probs.cpu())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.numpy())\n",
        "            else:\n",
        "                probs = torch.sigmoid(outputs)\n",
        "                preds = (probs > 0.5).long().squeeze(1)\n",
        "                all_probs.append(probs.cpu())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.numpy())\n",
        "\n",
        "    all_probs = torch.cat(all_probs, dim=0)\n",
        "    return all_labels, all_preds, all_probs\n",
        "\n",
        "def plot_confusion_matrix(true_labels, pred_labels, class_names):\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "def model_complexity(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"\\nModel Complexity: {total_params:,} trainable parameters\")\n",
        "\n",
        "def evaluate_model(model, dataloader, class_names, device, problem_type=\"multiclass\"):\n",
        "    '''\n",
        "    Prints all the metrics\n",
        "    '''\n",
        "    true_labels, pred_labels, probs = get_predictions(\n",
        "        model, dataloader, device, problem_type=problem_type\n",
        "    )\n",
        "\n",
        "    true_labels = torch.tensor(true_labels)\n",
        "    pred_labels = torch.tensor(pred_labels)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "    f1_macro = f1_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(true_labels, pred_labels, average='micro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"F1-score (macro):    {f1_macro:.4f}\")\n",
        "    print(f\"F1-score (micro):    {f1_micro:.4f}\")\n",
        "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
        "\n",
        "    print(\"\\n=== Classification Report ===\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=class_names, zero_division=0))\n",
        "\n",
        "    plot_confusion_matrix(true_labels, pred_labels, class_names)\n",
        "    model_complexity(model)\n",
        "\n",
        "    return true_labels, pred_labels, probs\n",
        "\n",
        "def get_metrics_for_table(model, dataloader, device, problem_type=\"multiclass\"):\n",
        "    \"\"\"\n",
        "    Returns only the numeric metrics needed for comparison tables.\n",
        "    No prints, no plots — clean output.\n",
        "    \"\"\"\n",
        "    true_labels, pred_labels, probs = get_predictions(\n",
        "        model, dataloader, device, problem_type=problem_type\n",
        "    )\n",
        "\n",
        "    # Convert to tensors\n",
        "    y_true = torch.tensor(true_labels)\n",
        "    y_pred = torch.tensor(pred_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"f1_micro\": f1_micro,\n",
        "        \"f1_weighted\": f1_weighted\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Robustly ensure `all_classes` and `idx_to_classes` are available ---\n",
        "# This block should only run if these variables are not already defined in the kernel.\n",
        "if 'all_classes' not in globals() or 'idx_to_classes' not in globals():\n",
        "    print(\"\\u26a0\\ufe0f `all_classes` or `idx_to_classes` not found. Attempting to reload data components.\")\n",
        "    from pathlib import Path\n",
        "    import json\n",
        "\n",
        "    # Assuming data is extracted at /content/InfraredSolarModules\n",
        "    data_dir = Path(\"/content/InfraredSolarModules\")\n",
        "    meta_path = data_dir / \"module_metadata.json\"\n",
        "\n",
        "    if not meta_path.exists():\n",
        "        print(\"\\u274c Metadata file not found. Please ensure the dataset is downloaded and extracted correctly.\")\n",
        "        # Fallback to empty values or raise an error if critical for proceeding\n",
        "        all_classes = []\n",
        "        idx_to_classes = {}\n",
        "    else:\n",
        "        with open(meta_path, \"r\") as f:\n",
        "            metadata = json.load(f)\n",
        "        all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "        idx_to_classes = {idx: cls for idx, cls in enumerate(all_classes)}\n",
        "    print(\"\\u2714\\ufe0f `all_classes` and `idx_to_classes` are now defined.\")\n",
        "\n",
        "\n",
        "# 1. Initialize an empty list to store K-fold results\n",
        "kfold_results = []\n",
        "\n",
        "# 2. Loop through the kfold_loaders\n",
        "for fold, loaders in enumerate(kfold_loaders):\n",
        "    print(f\"\\n=== Starting Fold {fold+1}/{len(kfold_loaders)} ===\")\n",
        "    train_loader = loaders['train']\n",
        "    val_loader = loaders['val']\n",
        "\n",
        "    # b. Instantiate a new NetworkCNN model (Model C)\n",
        "    model_C_kfold = NetworkCNN(num_classes=len(all_classes)).to(DEVICE)\n",
        "\n",
        "    # c. Define the loss function and the optimizer\n",
        "    loss_C_kfold = nn.CrossEntropyLoss()\n",
        "    optimizer_C_kfold = torch.optim.SGD(\n",
        "        model_C_kfold.parameters(),\n",
        "        lr=0.005,\n",
        "        momentum=0.9\n",
        "    )\n",
        "\n",
        "    # d. Call the train function\n",
        "    train_losses_C, train_accs_C, val_losses_C, val_accs_C, best_val_acc_C, best_epoch_C = train(\n",
        "        model=model_C_kfold,\n",
        "        train_dataloader=train_loader,\n",
        "        val_dataloader=val_loader,\n",
        "        loss_fn=loss_C_kfold,\n",
        "        optimizer=optimizer_C_kfold,\n",
        "        device=DEVICE,\n",
        "        num_epochs=20, # Reduced epochs for faster execution in K-fold\n",
        "        path_model=f\"model_C_fold_{fold+1}.pth\",\n",
        "        problem_type=\"multiclass\",\n",
        "        verbatim=False\n",
        "    )\n",
        "\n",
        "    print(f\"Fold {fold+1} - Best Validation Accuracy: {best_val_acc_C:.4f} at Epoch {best_epoch_C+1}\")\n",
        "\n",
        "    # e. Load the best model for evaluation\n",
        "    model_C_kfold.load_state_dict(torch.load(f\"model_C_fold_{fold+1}.pth\", map_location=DEVICE))\n",
        "    model_C_kfold.eval() # Set model to evaluation mode\n",
        "\n",
        "    # f. Use the get_metrics_for_table function to retrieve validation metrics\n",
        "    metrics_fold = get_metrics_for_table(\n",
        "        model=model_C_kfold,\n",
        "        dataloader=val_loader,\n",
        "        device=DEVICE,\n",
        "        problem_type=\"multiclass\"\n",
        "    )\n",
        "\n",
        "    # g. Append the calculated metrics to the kfold_results list\n",
        "    kfold_results.append({\"fold\": fold + 1, **metrics_fold})\n",
        "\n",
        "# 3. After the loop, print the kfold_results\n",
        "print(\"\\n=== K-Fold Cross-Validation Results ===\")\n",
        "for result in kfold_results:\n",
        "    print(f\"Fold {result['fold']}: Accuracy={result['accuracy']:.4f}, F1 Macro={result['f1_macro']:.4f}, F1 Weighted={result['f1_weighted']:.4f}\")\n",
        "\n",
        "# Optionally, calculate and print average metrics\n",
        "if kfold_results:\n",
        "    avg_accuracy = np.mean([r['accuracy'] for r in kfold_results])\n",
        "    avg_f1_macro = np.mean([r['f1_macro'] for r in kfold_results])\n",
        "    avg_f1_weighted = np.mean([r['f1_weighted'] for r in kfold_results])\n",
        "    print(f\"\\nAverage Metrics Across {len(kfold_loaders)} Folds:\")\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Average F1 Macro: {avg_f1_macro:.4f}\")\n",
        "    print(f\"Average F1 Weighted: {avg_f1_weighted:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "RFxmpB0MBAjj",
        "outputId": "5c4b6b3d-808b-40e8-eb01-ff945733fa8c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'kfold_loaders' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-311723826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;31m# 2. Loop through the kfold_loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold_loaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== Starting Fold {fold+1}/{len(kfold_loaders)} ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kfold_loaders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ff7f96b",
        "outputId": "b630b1f7-13ab-4b36-b750-5db38b3a1305"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd # Ensure pandas is imported for DataFrame operations\n",
        "\n",
        "print(\"Calculating sample weights for WeightedRandomSampler...\")\n",
        "\n",
        "# 1. Get class counts from the original, imbalanced train_df\n",
        "# Ensure `train_df` is available from the previous step\n",
        "if 'train_df' not in globals():\n",
        "    raise RuntimeError(\"Error: `train_df` not found. Please ensure the previous step to load original data was executed.\")\n",
        "\n",
        "class_counts = train_df['label'].value_counts().sort_index()\n",
        "print(\"Original class counts:\", class_counts.to_dict())\n",
        "\n",
        "# 2. Calculate class frequencies (proportion of each class in the dataset)\n",
        "# Ensure all possible classes are covered, even if some have zero counts in the current train_df subset\n",
        "# Use `num_classes` from previous cells or infer it\n",
        "if 'num_classes' not in globals():\n",
        "    if 'all_classes' in globals():\n",
        "        num_classes = len(all_classes)\n",
        "    else:\n",
        "        num_classes = train_df['label'].nunique() # Fallback, but ideally from `all_classes`\n",
        "    print(f\"⚠️ `num_classes` not found, inferred as {num_classes}.\")\n",
        "\n",
        "# Create a Series with all classes and their counts, filling missing with 0\n",
        "all_class_counts = pd.Series(0, index=range(num_classes))\n",
        "all_class_counts.update(class_counts)\n",
        "\n",
        "class_frequencies = all_class_counts / len(train_df)\n",
        "# Replace 0 frequencies with a small epsilon to avoid division by zero for weights if a class is completely missing\n",
        "class_frequencies = class_frequencies.replace(0, np.finfo(float).eps)\n",
        "\n",
        "print(\"Class frequencies:\", class_frequencies.to_dict())\n",
        "\n",
        "# 3. Calculate inverse class frequencies (weights for each class)\n",
        "# The weight for a class is inversely proportional to its frequency\n",
        "class_weights = 1.0 / class_frequencies\n",
        "print(\"Class weights (inverse frequencies):\", class_weights.to_dict())\n",
        "\n",
        "# 4. Map these class weights to each sample in the train_df\n",
        "sample_weights = [class_weights[label] for label in train_df['label']]\n",
        "sample_weights = torch.DoubleTensor(sample_weights)\n",
        "\n",
        "print(\"✔️ Sample weights calculated and converted to PyTorch DoubleTensor.\")\n",
        "print(f\"First 5 sample weights: {sample_weights[:5].tolist()}\")\n",
        "print(f\"Total number of sample weights: {len(sample_weights)}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating sample weights for WeightedRandomSampler...\n",
            "Original class counts: {0: 1502, 1: 1030, 2: 752, 3: 1199, 4: 140, 5: 199, 6: 197, 7: 8000, 8: 662, 9: 845, 10: 163, 11: 1311}\n",
            "Class frequencies: {0: 0.093875, 1: 0.064375, 2: 0.047, 3: 0.0749375, 4: 0.00875, 5: 0.0124375, 6: 0.0123125, 7: 0.5, 8: 0.041375, 9: 0.0528125, 10: 0.0101875, 11: 0.0819375}\n",
            "Class weights (inverse frequencies): {0: 10.652463382157125, 1: 15.533980582524272, 2: 21.27659574468085, 3: 13.344453711426187, 4: 114.28571428571428, 5: 80.40201005025125, 6: 81.21827411167513, 7: 2.0, 8: 24.16918429003021, 9: 18.93491124260355, 10: 98.15950920245399, 11: 12.204424103737605}\n",
            "✔️ Sample weights calculated and converted to PyTorch DoubleTensor.\n",
            "First 5 sample weights: [12.204424103737605, 13.344453711426187, 2.0, 2.0, 18.93491124260355]\n",
            "Total number of sample weights: 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Extract the metrics from the kfold_results list\n",
        "accuracies = [result['accuracy'] for result in kfold_results]\n",
        "f1_macros = [result['f1_macro'] for result in kfold_results]\n",
        "f1_weighted = [result['f1_weighted'] for result in kfold_results]\n",
        "\n",
        "# 2. Calculate the mean and standard deviation for each metric\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "\n",
        "mean_f1_macro = np.mean(f1_macros)\n",
        "std_f1_macro = np.std(f1_macros)\n",
        "\n",
        "mean_f1_weighted = np.mean(f1_weighted)\n",
        "std_f1_weighted = np.std(f1_weighted)\n",
        "\n",
        "# 3. Print the mean and standard deviation for each metric\n",
        "print(\"\\n=== Aggregated K-Fold Results ===\")\n",
        "print(f\"Accuracy: Mean = {mean_accuracy:.4f}, Std = {std_accuracy:.4f}\")\n",
        "print(f\"F1 Macro: Mean = {mean_f1_macro:.4f}, Std = {std_f1_macro:.4f}\")\n",
        "print(f\"F1 Weighted: Mean = {mean_f1_weighted:.4f}, Std = {std_f1_weighted:.4f}\")\n",
        "\n",
        "# Display as a DataFrame for better readability\n",
        "aggregated_metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'F1 Macro', 'F1 Weighted'],\n",
        "    'Mean': [mean_accuracy, mean_f1_macro, mean_f1_weighted],\n",
        "    'Standard Deviation': [std_accuracy, std_f1_macro, std_f1_weighted]\n",
        "})\n",
        "display(aggregated_metrics_df.round(4))"
      ],
      "metadata": {
        "id": "WyOFxI1oBQbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART B: Create Results"
      ],
      "metadata": {
        "id": "CY6EUsUHkTAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Create Model A, B, C specific dataframes with label conversion ---"
      ],
      "metadata": {
        "id": "lC4U758lMc6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model A (Binary Classification: No-Anomaly vs Anomaly)\n",
        "train_df_A = train_df.copy()\n",
        "train_df_A[\"label\"] = train_df_A[\"label\"].apply(lambda x: 0 if x==\"No-Anomaly\" else 1)\n",
        "\n",
        "test_df_A = test_df.copy()\n",
        "test_df_A[\"label\"] = test_df_A[\"label\"].apply(lambda x: 0 if x==\"No-Anomaly\" else 1)\n",
        "print(\"✔️ Model A dataframes created.\")\n",
        "\n",
        "# Model B (Multiclass Classification: 11 Anomaly Classes, 'No-Anomaly' removed)\n",
        "train_df_B = train_df[train_df[\"label\"]!=\"No-Anomaly\"].copy()\n",
        "test_df_B  = test_df[test_df[\"label\"]!=\"No-Anomaly\"].copy()\n",
        "\n",
        "# Create a new classes_map for Model B (11 classes) and convert labels to integers\n",
        "class_names_B = sorted([cls for cls in all_classes if cls != 'No-Anomaly'])\n",
        "classes_map_B = {cls: idx for idx, cls in enumerate(class_names_B)}\n",
        "\n",
        "train_df_B[\"label\"] = train_df_B[\"label\"].map(classes_map_B)\n",
        "test_df_B[\"label\"] = test_df_B[\"label\"].map(classes_map_B)\n",
        "print(\"✔️ Model B dataframes created.\")\n",
        "\n",
        "# Model C (Multiclass Classification: All 12 Original Classes)\n",
        "train_df_C = train_df.copy()\n",
        "test_df_C  = test_df.copy()\n",
        "\n",
        "# Convert string labels to integer indices for Model C dataframes using the original classes_map\n",
        "train_df_C[\"label\"] = train_df_C[\"label\"].map(classes_map)\n",
        "test_df_C[\"label\"] = test_df_C[\"label\"].map(classes_map)\n",
        "print(\"✔️ Model C dataframes created.\")"
      ],
      "metadata": {
        "id": "J1SEwPZTTHzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee3c97b-afa1-48c9-a70d-06ff4aa81ef9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Model A dataframes created.\n",
            "✔️ Model B dataframes created.\n",
            "✔️ Model C dataframes created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0PKct498MjS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Create SolarDataset instances with new transforms ---\n",
        "train_A = SolarDataset(train_df_A, transform=transform)\n",
        "test_A  = SolarDataset(test_df_A, transform=transform)\n",
        "\n",
        "train_B = SolarDataset(train_df_B, transform=transform)\n",
        "test_B  = SolarDataset(test_df_B, transform=transform)\n",
        "\n",
        "train_C = SolarDataset(train_df_C, transform=transform)\n",
        "test_C  = SolarDataset(test_df_C, transform=transform)\n",
        "\n",
        "print(\"✔️ SolarDataset instances updated with `train_transform` and `val_test_transform`.\")"
      ],
      "metadata": {
        "id": "SDKBaQXoT9JK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93032b8-d6ca-4651-d658-b5336b895306"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ SolarDataset instances updated with `train_transform` and `val_test_transform`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_conditional_generator_definition",
        "outputId": "a0bdafd8-00a8-4843-fc97-a723acbd1d92"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from PIL import Image # For opening image files\n",
        "\n",
        "# Assuming `train_df`, `test_df`, `all_classes` are already loaded and available from previous cells.\n",
        "# If not, please run the relevant data loading and splitting cells.\n",
        "\n",
        "# Define image transformations for the dataset\n",
        "# This transform assumes grayscale images (1 channel)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), # Resize images to 64x64\n",
        "    transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "    transforms.Normalize(\n",
        "        mean=(0.5,),             # Normalize for 1-channel image (grayscale)\n",
        "        std=(0.5,)\n",
        "    )\n",
        "])\n",
        "\n",
        "# Define the custom SolarDataset class (reusing the logic from Annex 2)\n",
        "class SolarDataset(data.Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row[\"path\"]).convert(\"L\") # Open image and convert to grayscale\n",
        "        label = row[\"label\"]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Determine the number of classes (assuming `all_classes` is globally available)\n",
        "num_classes = len(all_classes)\n",
        "print(f\"Number of classes detected: {num_classes}\")\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = SolarDataset(train_df, transform=transform)\n",
        "test_dataset = SolarDataset(test_df, transform=transform)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32 # You can adjust this value\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,       # Shuffle training data\n",
        "    num_workers=2       # Number of subprocesses to use for data loading\n",
        ")\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,      # No need to shuffle test data\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"✔️ Training and Testing DataLoaders created with batch size {batch_size}.\")\n",
        "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in test_loader: {len(test_loader)}\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes detected: 12\n",
            "✔️ Training and Testing DataLoaders created with batch size 32.\n",
            "Number of batches in train_loader: 200\n",
            "Number of batches in test_loader: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annex"
      ],
      "metadata": {
        "id": "zIags6NdUBBV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0de1e46b"
      },
      "source": [
        "## Annex1 -> Clone to all access [Se calhar tira-se, é só pronto para depois tu dares pull e push]\n",
        "This cell performs all necessary Git operations to set up your environment, synchronize with your GitHub repository, and push changes. It's designed to be robust for fresh Colab sessions.\n",
        "\n",
        "**Before running:**\n",
        "\n",
        "2.  Ensure that token, nameGit, repo and email is saved on collab secrets **and** the `REPO_FOLDER`, `GITHUB_USERNAME`, `GIT_USER_NAME`, and `GIT_USER_EMAIL` variables below if they differ from your setup."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Configuration Variables ---\n",
        "# Retrieve values from Colab Secrets as specified by the user\n",
        "REPO_FOLDER = userdata.get('repo')  # Name of your repository folder\n",
        "GITHUB_USERNAME = userdata.get('nameGit') # Your GitHub username\n",
        "GIT_USER_NAME = userdata.get('nameGit') # Name for Git commits\n",
        "GIT_USER_EMAIL = userdata.get('email') # Email for Git commits\n",
        "commit_message = \"Automated update from Colab session\" # Default commit message\n",
        "\n",
        "# --- 1. Configure Git User ---\n",
        "print(\"Configuring Git user...\")\n",
        "!git config --global user.name \"{GIT_USER_NAME}\"\n",
        "!git config --global user.email \"{GIT_USER_EMAIL}\"\n",
        "print(\"✔️ Git user configured.\")\n",
        "\n",
        "# --- 2. Retrieve GitHub PAT from Colab Secrets ---\n",
        "print(\"Attempting to retrieve GitHub PAT from Colab Secrets...\")\n",
        "GITHUB_PAT = None\n",
        "try:\n",
        "    pat_from_secrets = userdata.get('token')\n",
        "    if pat_from_secrets:\n",
        "        GITHUB_PAT = pat_from_secrets\n",
        "        print(\"✔️ GitHub PAT retrieved successfully. Full push/pull access will be enabled.\")\n",
        "    else:\n",
        "        print(\"❌ GitHub PAT not found in Colab Secrets. Full Git operations aborted.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error retrieving PAT: {e}. Full Git operations aborted.\")\n",
        "\n",
        "# Proceed only if PAT is successfully retrieved and essential configs are present\n",
        "if GITHUB_PAT and REPO_FOLDER and GITHUB_USERNAME:\n",
        "    repo_path = f\"/content/{REPO_FOLDER}\"\n",
        "    remote_repo_url = f\"https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{REPO_FOLDER}.git\"\n",
        "\n",
        "    # --- 3. Clone or Pull Repository ---\n",
        "    if os.path.exists(repo_path):\n",
        "        print(f\"Repository '{REPO_FOLDER}' already exists. Attempting to pull latest changes...\")\n",
        "        %cd {repo_path}\n",
        "        !git pull\n",
        "        print(f\"✔️ Pulled latest changes for '{REPO_FOLDER}'.\")\n",
        "    else:\n",
        "        print(f\"Cloning repository '{REPO_FOLDER}'...\")\n",
        "        %cd /content/\n",
        "        !git clone {remote_repo_url}\n",
        "        print(f\"✔️ Cloned repository '{REPO_FOLDER}'.\")\n",
        "\n",
        "    # Change into the repository directory for further operations\n",
        "    %cd {repo_path}\n",
        "\n",
        "    # --- 4. Add, Commit, and Push Changes ---\n",
        "    print(\"Adding all changes to Git staging area...\")\n",
        "    !git add .\n",
        "\n",
        "    print(\"Committing changes...\")\n",
        "    status_output = !git status --porcelain\n",
        "    if status_output:\n",
        "        !git commit -m \"{commit_message}\"\n",
        "        print(\"✔️ Changes committed.\")\n",
        "\n",
        "        print(\"Pushing changes to GitHub...\")\n",
        "        !git push\n",
        "        print(\"✔️ Changes pushed to GitHub.\")\n",
        "    else:\n",
        "        print(\"ℹ️ No changes to commit.\")\n",
        "\n",
        "    # --- 5. Return to original working directory ---\n",
        "    %cd /content/\n",
        "\n",
        "    print(\"\\n✅ Git operations complete.\")\n",
        "else:\n",
        "    print(\"\\n❌ Full Git operations aborted: Missing PAT, REPO_FOLDER, or GITHUB_USERNAME configuration.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItQBG5mFWXwB",
        "outputId": "978dfbe0-88cd-4e2c-a0ba-bb0a4abe4b55"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuring Git user...\n",
            "✔️ Git user configured.\n",
            "Attempting to retrieve GitHub PAT from Colab Secrets...\n",
            "✔️ GitHub PAT retrieved successfully. Full push/pull access will be enabled.\n",
            "Repository 'VC_0312' already exists. Attempting to pull latest changes...\n",
            "/content/VC_0312\n",
            "Already up to date.\n",
            "✔️ Pulled latest changes for 'VC_0312'.\n",
            "/content/VC_0312\n",
            "Adding all changes to Git staging area...\n",
            "Committing changes...\n",
            "ℹ️ No changes to commit.\n",
            "/content\n",
            "\n",
            "✅ Git operations complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annex 2: Train/Test Split"
      ],
      "metadata": {
        "id": "_Ijsf4TR-Em5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb90abe7",
        "outputId": "0401f093-3848-4623-c51a-8869bcead0a3"
      },
      "source": [
        "# --- 2. Create DataFrame with 'path' and class mappings ---\n",
        "all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "\n",
        "rows = []\n",
        "for img_id, info in metadata.items():\n",
        "    full_image_path = data_dir / info[\"image_filepath\"]\n",
        "    # Store original class name as 'class_name' and map to numerical 'label'\n",
        "    rows.append({\"img_id\": img_id, \"class_name\": info[\"anomaly_class\"], \"path\": str(full_image_path)})\n",
        "df = pd.DataFrame(rows)\n",
        "df['label'] = df['class_name'].map(classes_map)\n",
        "\n",
        "print(\"✔️ DataFrame created with 'path', 'class_name', and 'label' columns.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ DataFrame created with 'path', 'class_name', and 'label' columns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "2a8609d0",
        "outputId": "0e5579f0-85f0-4c95-8789-d507cebba9e8"
      },
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assume 'df', 'classes_map', 'idx_to_classes' are available from previous cells.\n",
        "# If not, the robust data loading block below will ensure they are.\n",
        "\n",
        "# Robustly ensure necessary data components are available (copying from d8d96e4e/8ZmpUbIifYSp)\n",
        "if 'df' not in globals() or 'classes_map' not in globals() or 'idx_to_classes' not in globals():\n",
        "    print(\"⚠️ Necessary data components not found. Attempting to reload data components.\")\n",
        "    data_root_dir = Path(\"/content/InfraredSolarModules\")\n",
        "    data_dir = Path(\"/content/InfraredSolarModules\") # Assuming this is consistent\n",
        "    meta_path = data_dir / \"module_metadata.json\"\n",
        "\n",
        "    if not meta_path.exists():\n",
        "        raise FileNotFoundError(\"Metadata file not found. Please ensure the dataset is downloaded and extracted correctly.\")\n",
        "\n",
        "    with open(meta_path, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "    classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "    idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "\n",
        "    rows = []\n",
        "    for img_id, info in metadata.items():\n",
        "        full_image_path = data_dir / info[\"image_filepath\"]\n",
        "        rows.append({\"img_id\": img_id, \"class_name\": info[\"anomaly_class\"], \"path\": str(full_image_path)}) # Store original class name\n",
        "    df = pd.DataFrame(rows)\n",
        "    df['label'] = df['class_name'].map(classes_map) # Add numerical label to main df\n",
        "\n",
        "    print(\"✔️ Basic data components reloaded/recalculated.\")\n",
        "\n",
        "\n",
        "# Perform initial train_test_split on the main df (which now has path, class_name, and numerical label)\n",
        "full_train_df, final_test_df_C = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['label'], # Stratify by numerical label\n",
        "    random_state=42\n",
        ")\n",
        "full_train_df = full_train_df.reset_index(drop=True)\n",
        "final_test_df_C = final_test_df_C.reset_index(drop=True)\n",
        "\n",
        "# The 'label' column in full_train_df and final_test_df_C is already numerical due to stratify=df['label']\n",
        "# and df['label'] being numerical. The 'class_name' column is also present.\n",
        "\n",
        "print(\"✔️ Data components reloaded/recalculated.\")\n",
        "\n",
        "\n",
        "# --- Process full_train_df for export ---\n",
        "print(\"\\nProcessing full_train_df for export...\")\n",
        "# Select relevant columns for the export CSV\n",
        "full_train_export_df = full_train_df[['path', 'class_name', 'label']].copy()\n",
        "full_train_export_df.to_csv('full_train_data_list.csv', index=False)\n",
        "print(\"✔️ `full_train_data_list.csv` created with 'path', 'class_name', 'label'.\")\n",
        "display(full_train_export_df.head())\n",
        "\n",
        "# --- Process final_test_df_C for export ---\n",
        "print(\"\\nProcessing final_test_df_C for export...\")\n",
        "# Select relevant columns for the export CSV\n",
        "final_test_export_df = final_test_df_C[['path', 'class_name', 'label']].copy()\n",
        "final_test_export_df.to_csv('final_test_data_list.csv', index=False)\n",
        "print(\"✔️ `final_test_data_list.csv` created with 'path', 'class_name', 'label'.\")\n",
        "display(final_test_export_df.head())\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Data components reloaded/recalculated.\n",
            "\n",
            "Processing full_train_df for export...\n",
            "✔️ `full_train_data_list.csv` created with 'path', 'class_name', 'label'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             path  class_name  label\n",
              "0   /content/InfraredSolarModules/images/9145.jpg  Vegetation     11\n",
              "1   /content/InfraredSolarModules/images/1178.jpg       Diode      3\n",
              "2  /content/InfraredSolarModules/images/14418.jpg  No-Anomaly      7\n",
              "3  /content/InfraredSolarModules/images/17272.jpg  No-Anomaly      7\n",
              "4   /content/InfraredSolarModules/images/3301.jpg   Shadowing      9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-116f6d7f-eebc-44bb-80bb-024dfea6a137\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/InfraredSolarModules/images/9145.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/InfraredSolarModules/images/1178.jpg</td>\n",
              "      <td>Diode</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/InfraredSolarModules/images/14418.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/InfraredSolarModules/images/17272.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/InfraredSolarModules/images/3301.jpg</td>\n",
              "      <td>Shadowing</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-116f6d7f-eebc-44bb-80bb-024dfea6a137')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-116f6d7f-eebc-44bb-80bb-024dfea6a137 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-116f6d7f-eebc-44bb-80bb-024dfea6a137');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a45f0530-070a-4a41-8bba-27e22ed6e8c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a45f0530-070a-4a41-8bba-27e22ed6e8c6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a45f0530-070a-4a41-8bba-27e22ed6e8c6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(final_test_export_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/InfraredSolarModules/images/1178.jpg\",\n          \"/content/InfraredSolarModules/images/3301.jpg\",\n          \"/content/InfraredSolarModules/images/14418.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Diode\",\n          \"Shadowing\",\n          \"Vegetation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing final_test_df_C for export...\n",
            "✔️ `final_test_data_list.csv` created with 'path', 'class_name', 'label'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             path  class_name  label\n",
              "0   /content/InfraredSolarModules/images/8857.jpg  Vegetation     11\n",
              "1   /content/InfraredSolarModules/images/8573.jpg  Vegetation     11\n",
              "2   /content/InfraredSolarModules/images/2303.jpg       Diode      3\n",
              "3  /content/InfraredSolarModules/images/17675.jpg  No-Anomaly      7\n",
              "4   /content/InfraredSolarModules/images/3989.jpg  Cell-Multi      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e4c3e59-25eb-470c-928e-15f9ac18946b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/InfraredSolarModules/images/8857.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/InfraredSolarModules/images/8573.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/InfraredSolarModules/images/2303.jpg</td>\n",
              "      <td>Diode</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/InfraredSolarModules/images/17675.jpg</td>\n",
              "      <td>No-Anomaly</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/InfraredSolarModules/images/3989.jpg</td>\n",
              "      <td>Cell-Multi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e4c3e59-25eb-470c-928e-15f9ac18946b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e4c3e59-25eb-470c-928e-15f9ac18946b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e4c3e59-25eb-470c-928e-15f9ac18946b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3b134478-ec4b-4310-a642-175aba5ea634\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b134478-ec4b-4310-a642-175aba5ea634')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3b134478-ec4b-4310-a642-175aba5ea634 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(final_test_export_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/InfraredSolarModules/images/8573.jpg\",\n          \"/content/InfraredSolarModules/images/3989.jpg\",\n          \"/content/InfraredSolarModules/images/2303.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Diode\",\n          \"Cell-Multi\",\n          \"Vegetation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f757b447",
        "outputId": "c5209b44-ee99-466c-f86c-740592605942"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "\n",
        "# --- Configuration Variables ---\n",
        "REPO_FOLDER = userdata.get('repo')\n",
        "GITHUB_USERNAME = userdata.get('nameGit')\n",
        "GIT_USER_NAME = userdata.get('nameGit')\n",
        "GIT_USER_EMAIL = userdata.get('email')\n",
        "GITHUB_PAT = userdata.get('token')\n",
        "\n",
        "# List of CSV files to push\n",
        "csv_filenames_to_push = [\"full_train_data_list.csv\", \"final_test_data_list.csv\"]\n",
        "general_commit_message = f\"Add data split CSV files: {', '.join(csv_filenames_to_push)}\"\n",
        "\n",
        "# --- Git and File Operations ---\n",
        "if REPO_FOLDER and GITHUB_USERNAME and GIT_USER_NAME and GIT_USER_EMAIL and GITHUB_PAT:\n",
        "    repo_path = Path(f\"/content/{REPO_FOLDER}\")\n",
        "    remote_repo_url = f\"https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{REPO_FOLDER}.git\"\n",
        "\n",
        "    if not repo_path.exists():\n",
        "        print(f\"❌ Repository '{REPO_FOLDER}' not found at {repo_path}. Please run the comprehensive Git setup cell first.\")\n",
        "    else:\n",
        "        print(f\"Navigating to repository: {repo_path}\")\n",
        "        %cd {repo_path}\n",
        "\n",
        "        # --- Assume DataFrames are already in globals and save them to /content/ ---\n",
        "        # This assumes `full_train_export_df` and `final_test_export_df` were created by a previous cell.\n",
        "        if 'full_train_export_df' in globals():\n",
        "            globals()['full_train_export_df'].to_csv('/content/full_train_data_list.csv', index=False)\n",
        "            print(\"✔️ 'full_train_export_df' saved to /content/full_train_data_list.csv.\")\n",
        "        else:\n",
        "            print(\"❌ 'full_train_export_df' not found in global scope. Cannot save. Please ensure cell 98f3411c has been executed.\")\n",
        "\n",
        "        if 'final_test_export_df' in globals():\n",
        "            globals()['final_test_export_df'].to_csv('/content/final_test_data_list.csv', index=False)\n",
        "            print(\"✔️ 'final_test_export_df' saved to /content/final_test_data_list.csv.\")\n",
        "        else:\n",
        "            print(\"❌ 'final_test_export_df' not found in global scope. Cannot save. Please ensure cell 98f3411c has been executed.\")\n",
        "\n",
        "\n",
        "        for csv_filename in csv_filenames_to_push:\n",
        "            source_csv_path = Path(\"/content\") / csv_filename\n",
        "            destination_csv_path = repo_path / csv_filename\n",
        "\n",
        "            if source_csv_path.exists():\n",
        "                if not destination_csv_path.exists() or (destination_csv_path.exists() and source_csv_path.read_bytes() != destination_csv_path.read_bytes()):\n",
        "                    print(f\"Copying '{csv_filename}' to repository...\")\n",
        "                    shutil.copy(source_csv_path, destination_csv_path)\n",
        "                    print(f\"✔️ '{csv_filename}' copied.\")\n",
        "\n",
        "                    print(f\"Adding '{csv_filename}' to Git staging area...\")\n",
        "                    !git add {csv_filename}\n",
        "                else:\n",
        "                    print(f\"ℹ️ '{csv_filename}' already exists and is identical in the repository. Skipping add.\")\n",
        "            else:\n",
        "                print(f\"❌ Source file '{source_csv_path}' not found. Cannot add/push. Please ensure the DataFrame was saved.\")\n",
        "\n",
        "        print(\"Committing changes...\")\n",
        "        !git config user.name \"{GIT_USER_NAME}\"\n",
        "        !git config user.email \"{GIT_USER_EMAIL}\"\n",
        "\n",
        "        status_output = !git status --porcelain\n",
        "        if status_output:\n",
        "            commit_output = !git commit -m \"{general_commit_message}\"\n",
        "            print(\"✔️ Changes committed.\")\n",
        "\n",
        "            print(\"Pushing changes to GitHub...\")\n",
        "            !git push {remote_repo_url}\n",
        "            print(\"✔️ Changes pushed to GitHub.\")\n",
        "        else:\n",
        "            print(\"ℹ️ No changes to commit.\")\n",
        "\n",
        "        %cd /content/\n",
        "\n",
        "        print(\"\\n✅ Git operations complete.\")\n",
        "else:\n",
        "    print(\"\\n❌ Git operations aborted due to missing configuration from Colab Secrets. Ensure 'repo', 'nameGit', 'email', and 'token' are set.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Navigating to repository: /content/VC_0312\n",
            "/content/VC_0312\n",
            "✔️ 'full_train_export_df' saved to /content/full_train_data_list.csv.\n",
            "✔️ 'final_test_export_df' saved to /content/final_test_data_list.csv.\n",
            "ℹ️ 'full_train_data_list.csv' already exists and is identical in the repository. Skipping add.\n",
            "ℹ️ 'final_test_data_list.csv' already exists and is identical in the repository. Skipping add.\n",
            "Committing changes...\n",
            "ℹ️ No changes to commit.\n",
            "/content\n",
            "\n",
            "✅ Git operations complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annex3_GAN_Creation"
      ],
      "metadata": {
        "id": "YqlBCwNdVbDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure the train that the GAN has acess, it is the same used on the multiple Models, a list was made."
      ],
      "metadata": {
        "id": "LwSJic2eVjSE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8d96e4e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image # Import Image for SolarDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data\n",
        "\n",
        "import os\n",
        "\n",
        "# --- Control Flag for Annex Execution ---\n",
        "# This flag is defined in a separate control cell. If not found, default to False.\n",
        "_RUN_ANNEXES = globals().get('_RUN_ANNEXES', False)\n",
        "\n",
        "if _RUN_ANNEXES:\n",
        "    print(\"Executing Annex GAN Operations...\")\n",
        "    # --- Redefine DEVICE ---\n",
        "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # --- Re-define cGAN Hyperparameters ---\n",
        "    z_dim = 100  # Size of the latent vector\n",
        "    num_epochs = 50 # Number of training epochs\n",
        "    lr_g = 0.0002 # Learning rate for the Generator\n",
        "    lr_d = 0.0002 # Learning rate for the Discriminator\n",
        "    beta1 = 0.5  # Beta1 hyperparameter for Adam optimizers\n",
        "    img_channels = 1 # Number of channels in the training images (grayscale)\n",
        "\n",
        "    # --- Robustly ensure data components are available ---\n",
        "    # This block ensures all necessary dataframes, mappings, and counts are defined\n",
        "    if 'all_classes' not in globals() or 'idx_to_classes' not in globals() or \\\n",
        "      'full_train_df' not in globals() or 'original_counts_full_train' not in globals() or \\\n",
        "      'effective_count_per_class_full_train' not in globals():\n",
        "        print(\"\\u26a0\\ufe0f Necessary data components not found. Attempting to reload data components.\")\n",
        "\n",
        "        data_root_dir = Path(\"/content/InfraredSolarModules\")\n",
        "        if not data_root_dir.exists() or not any(data_root_dir.iterdir()):\n",
        "            print(\"Downloading and extracting dataset...\")\n",
        "            !rm -rf /content/*\n",
        "            !wget -q -O /content/infrared.zip \\\n",
        "              \"https://github.com/RaptorMaps/InfraredSolarModules/raw/master/2020-02-14_InfraredSolarModules.zip\"\n",
        "            !unzip -q /content/infrared.zip -d /content/\n",
        "            print(\"Dataset downloaded and extracted.\")\n",
        "        else:\n",
        "            print(\"Dataset already present, skipping download and extraction.\")\n",
        "\n",
        "        data_dir = Path(\"/content/InfraredSolarModules\")\n",
        "        meta_path = data_dir / \"module_metadata.json\"\n",
        "        with open(meta_path, \"r\") as f:\n",
        "            metadata = json.load(f)\n",
        "\n",
        "        all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "        classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "        idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "\n",
        "        rows = []\n",
        "        for img_id, info in metadata.items():\n",
        "            full_image_path = data_dir / info[\"image_filepath\"]\n",
        "            rows.append({\"img_id\": img_id, \"label\": info[\"anomaly_class\"], \"path\": str(full_image_path)})\n",
        "        df = pd.DataFrame(rows)\n",
        "\n",
        "        # Re-perform initial train_test_split\n",
        "        full_train_df, _ = train_test_split(\n",
        "            df,\n",
        "            test_size=0.2,\n",
        "            stratify=df['label'],\n",
        "            random_state=42\n",
        "        )\n",
        "        full_train_df = full_train_df.reset_index(drop=True)\n",
        "        full_train_df['label'] = full_train_df['label'].map(classes_map)\n",
        "\n",
        "        # Re-calculate original_counts_full_train and effective_count_per_class_full_train\n",
        "        original_counts_full_train = full_train_df['label'].value_counts().sort_index()\n",
        "        effective_count_per_class_full_train = original_counts_full_train.max()\n",
        "\n",
        "        print(\"\\u2714\\ufe0f Data components reloaded/recalculated.\")\n",
        "\n",
        "    num_classes = len(all_classes)\n",
        "\n",
        "    # --- Redefine simplified transforms ---\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.Normalize(\n",
        "            mean=(0.5,),\n",
        "            std=(0.5,))])\n",
        "\n",
        "    # --- Redefine SolarDataset class ---\n",
        "    class SolarDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, df, transform=None):\n",
        "            self.df = df.reset_index(drop=True)\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.df)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            row = self.df.iloc[idx]\n",
        "            image = Image.open(row[\"path\"]).convert(\"L\")\n",
        "            label = row[\"label\"]\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "\n",
        "    # --- Prepare cGAN Dataset and DataLoader ---\n",
        "    # 1. Identify the minority classes\n",
        "    minority_class_indices = original_counts_full_train[original_counts_full_train < effective_count_per_class_full_train].index.tolist()\n",
        "    minority_class_names = [idx_to_classes[idx] for idx in minority_class_indices]\n",
        "\n",
        "    # 2. Filter full_train_df to create minority_classes_df\n",
        "    minority_classes_df = full_train_df[full_train_df['label'].isin(minority_class_indices)].copy()\n",
        "\n",
        "    # 3. Create an instance of SolarDataset for cGAN training\n",
        "    cgan_train_dataset = SolarDataset(minority_classes_df, transform=train_transform)\n",
        "\n",
        "    # 4. Create a PyTorch DataLoader for cGAN training\n",
        "    cgan_train_loader = torch.utils.data.DataLoader(\n",
        "        cgan_train_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=True\n",
        "    )\n",
        "    print(\"\\u2714\\ufe0f `cgan_train_loader` (and dependencies) created.\")\n",
        "\n",
        "    # --- Re-define Generator and Discriminator classes ---\n",
        "\n",
        "    # Define cGAN Conditional Generator Network\n",
        "    class ConditionalGenerator(nn.Module):\n",
        "        def __init__(self, z_dim, img_channels, num_classes, embed_size=100):\n",
        "            super(ConditionalGenerator, self).__init__()\n",
        "            self.num_classes = num_classes\n",
        "            self.img_channels = img_channels\n",
        "            self.z_dim = z_dim\n",
        "            self.embed_size = embed_size\n",
        "\n",
        "            self.label_embedding = nn.Embedding(num_classes, embed_size)\n",
        "            self.input_dim = z_dim + embed_size\n",
        "\n",
        "            self.main = nn.Sequential(\n",
        "                nn.ConvTranspose2d(self.input_dim, 256, 4, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(32, img_channels, 4, 2, 1, bias=False),\n",
        "                nn.Tanh()\n",
        "            )\n",
        "\n",
        "        def forward(self, noise, labels):\n",
        "            label_embed = self.label_embedding(labels).view(-1, self.embed_size, 1, 1)\n",
        "            input_vec = torch.cat([noise, label_embed], 1)\n",
        "            return self.main(input_vec)\n",
        "\n",
        "    # Define cGAN Conditional Discriminator Network\n",
        "    class ConditionalDiscriminator(nn.Module):\n",
        "        def __init__(self, img_channels, num_classes, embed_size=100):\n",
        "            super(ConditionalDiscriminator, self).__init__()\n",
        "            self.num_classes = num_classes\n",
        "            self.img_channels = img_channels\n",
        "            self.embed_size = embed_size\n",
        "\n",
        "            self.label_embedding = nn.Embedding(num_classes, embed_size)\n",
        "\n",
        "            self.conv_layers = nn.Sequential(\n",
        "                nn.Conv2d(img_channels, 64, 4, 2, 1, bias=False),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "                nn.BatchNorm2d(512),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(512 * 4 * 4 + embed_size, 1024),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.Linear(1024, 1)\n",
        "            )\n",
        "\n",
        "        def forward(self, image, labels):\n",
        "            img_features = self.conv_layers(image)\n",
        "            img_features = torch.flatten(img_features, 1)\n",
        "            label_embed = self.label_embedding(labels)\n",
        "            combined_features = torch.cat([img_features, label_embed], 1)\n",
        "            output = self.fc(combined_features)\n",
        "            return output\n",
        "\n",
        "    # --- Re-define weights_init helper function ---\n",
        "    def weights_init(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find('Conv') != -1:\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find('BatchNorm') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "    # --- Re-define train_cgan function ---\n",
        "    def train_cgan(generator, discriminator, cgan_train_loader, z_dim, num_epochs, device, lr_g, lr_d, beta1, img_channels, num_classes, cgan_model_path=\"cgan_generator_minority_classes.pth\"):\n",
        "        generator.apply(weights_init)\n",
        "        discriminator.apply(weights_init)\n",
        "\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, 0.999))\n",
        "        optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(beta1, 0.999))\n",
        "\n",
        "        generator.to(device)\n",
        "        discriminator.to(device)\n",
        "\n",
        "        fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)\n",
        "        fixed_labels = torch.randint(0, num_classes, (64,), device=device)\n",
        "\n",
        "        print(\"Starting cGAN Training Loop...\")\n",
        "        for epoch in range(num_epochs):\n",
        "            for i, (real_images, labels) in enumerate(cgan_train_loader):\n",
        "                ############################\n",
        "                # (1) Update D network: maximize log(D(x | y)) + log(1 - D(G(z | y)))\n",
        "                ###########################\n",
        "                discriminator.zero_grad()\n",
        "                real_images = real_images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                b_size = real_images.size(0)\n",
        "\n",
        "                real_label = torch.full((b_size,), 1.0, dtype=torch.float, device=device)\n",
        "                fake_label = torch.full((b_size,), 0.0, dtype=torch.float, device=device)\n",
        "\n",
        "                output_real = discriminator(real_images, labels).view(-1)\n",
        "                errD_real = criterion(output_real, real_label)\n",
        "                errD_real.backward()\n",
        "                D_x = output_real.mean().item()\n",
        "\n",
        "                noise = torch.randn(b_size, z_dim, 1, 1, device=device)\n",
        "                fake_labels = labels # Use real labels as condition for generated fakes\n",
        "\n",
        "                fake_images = generator(noise, fake_labels)\n",
        "                output_fake = discriminator(fake_images.detach(), fake_labels).view(-1)\n",
        "                errD_fake = criterion(output_fake, fake_label)\n",
        "                errD_fake.backward()\n",
        "                D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "                errD = errD_real + errD_fake\n",
        "                optimizer_D.step()\n",
        "\n",
        "                ############################\n",
        "                # (2) Update G network: maximize log(D(G(z | y)))\n",
        "                ###########################\n",
        "                generator.zero_grad()\n",
        "                output_fake_for_G = discriminator(fake_images, fake_labels).view(-1)\n",
        "                errG = criterion(output_fake_for_G, real_label)\n",
        "                errG.backward()\n",
        "                D_G_z2 = output_fake_for_G.mean().item()\n",
        "                optimizer_G.step()\n",
        "\n",
        "                if i % 50 == 0:\n",
        "                    print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{i}/{len(cgan_train_loader)}]\tLoss_D: {errD.item():.4f}\tLoss_G: {errG.item():.4f}\tD(x): {D_x:.4f}\tD(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
        "\n",
        "            generator.eval()\n",
        "            with torch.no_grad():\n",
        "                fake_images_epoch = generator(fixed_noise, fixed_labels).detach().cpu()\n",
        "                vutils.save_image(fake_images_epoch, f\"cgan_generated_samples_epoch_{epoch+1:03d}.png\", normalize=True)\n",
        "            generator.train()\n",
        "\n",
        "        print(\"cGAN Training Complete!\")\n",
        "        torch.save(generator.state_dict(), cgan_model_path)\n",
        "        print(f\"Trained cGAN Generator saved to: {cgan_model_path}\")\n",
        "\n",
        "    print(\"\\n=== Training cGAN and Saving Generator ===\")\n",
        "\n",
        "    # 1. Initialize Generator and Discriminator\n",
        "    cgan_generator = ConditionalGenerator(z_dim, img_channels, num_classes).to(DEVICE)\n",
        "    cgan_discriminator = ConditionalDiscriminator(img_channels, num_classes).to(DEVICE)\n",
        "\n",
        "    # 2. Train the cGAN\n",
        "    train_cgan(\n",
        "        generator=cgan_generator,\n",
        "        discriminator=cgan_discriminator,\n",
        "        cgan_train_loader=cgan_train_loader,\n",
        "        z_dim=z_dim,\n",
        "        num_epochs=num_epochs,\n",
        "        device=DEVICE,\n",
        "        lr_g=lr_g,\n",
        "        lr_d=lr_d,\n",
        "        beta1=beta1,\n",
        "        img_channels=img_channels,\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "\n",
        "    print(\"\\u2714\\ufe0f cGAN training completed and generator saved.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Files Extracted to Github"
      ],
      "metadata": {
        "id": "ymCmXN5cdYI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "\n",
        "# --- Control Flag for Annex Execution ---\n",
        "# This flag is defined in a separate control cell. If not found, default to False.\n",
        "_RUN_ANNEXES = globals().get('_RUN_ANNEXES', False)\n",
        "\n",
        "if _RUN_ANNEXES:\n",
        "\n",
        "\n",
        "    # --- Configuration Variables ---\n",
        "    # Retrieve values from Colab Secrets (ensure these are set up)\n",
        "    REPO_FOLDER = userdata.get('repo')  # Name of your repository folder (e.g., 'VC_0312')\n",
        "    GITHUB_USERNAME = userdata.get('nameGit') # Your GitHub username\n",
        "    GIT_USER_NAME = userdata.get('nameGit') # Name for Git commits\n",
        "    GIT_USER_EMAIL = userdata.get('email') # Email for Git commits\n",
        "\n",
        "    csv_filename = \"cgan_training_data_list.csv\"\n",
        "    commit_message = f\"Add {csv_filename} with cGAN training data list\"\n",
        "\n",
        "    # --- Git and File Operations ---\n",
        "    if REPO_FOLDER and GITHUB_USERNAME and GIT_USER_NAME and GIT_USER_EMAIL:\n",
        "        repo_path = f\"/content/{REPO_FOLDER}\"\n",
        "        csv_path = f\"{repo_path}/{csv_filename}\"\n",
        "\n",
        "        if not os.path.exists(repo_path):\n",
        "            print(f\"❌ Repository '{REPO_FOLDER}' not found at {repo_path}. Please run the comprehensive Git setup cell first.\")\n",
        "        else:\n",
        "            print(f\"Navigating to repository: {repo_path}\")\n",
        "            %cd {repo_path}\n",
        "\n",
        "            # --- Ensure minority_classes_df_for_display is available ---\n",
        "            # This block reloads data if necessary to make minority_classes_df_for_display available\n",
        "            if 'minority_classes_df_for_display' not in globals():\n",
        "                print(\"\\u26a0\\ufe0f `minority_classes_df_for_display` not found. Attempting to reload data components to reconstruct it.\")\n",
        "                from pathlib import Path\n",
        "                import json\n",
        "                from sklearn.model_selection import train_test_split\n",
        "\n",
        "                data_root_dir = Path(\"/content/InfraredSolarModules\")\n",
        "                data_dir = Path(\"/content/InfraredSolarModules\")\n",
        "                meta_path = data_dir / \"module_metadata.json\"\n",
        "\n",
        "                if not meta_path.exists():\n",
        "                    print(\"\\u274c Metadata file not found. Please ensure the dataset is downloaded and extracted correctly.\")\n",
        "                    minority_classes_df_for_display = pd.DataFrame(columns=['path', 'class_name'])\n",
        "                else:\n",
        "                    with open(meta_path, \"r\") as f:\n",
        "                        metadata = json.load(f)\n",
        "\n",
        "                    all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "                    classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "                    idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "\n",
        "                    rows = []\n",
        "                    for img_id, info in metadata.items():\n",
        "                        full_image_path = data_dir / info[\"image_filepath\"]\n",
        "                        rows.append({\"img_id\": img_id, \"label\": info[\"anomaly_class\"], \"path\": str(full_image_path)})\n",
        "                    df = pd.DataFrame(rows)\n",
        "\n",
        "                    full_train_df, _ = train_test_split(\n",
        "                        df,\n",
        "                        test_size=0.2,\n",
        "                        stratify=df['label'],\n",
        "                        random_state=42\n",
        "                    )\n",
        "                    full_train_df = full_train_df.reset_index(drop=True)\n",
        "                    full_train_df['label'] = full_train_df['label'].map(classes_map)\n",
        "\n",
        "                    original_counts_full_train = full_train_df['label'].value_counts().sort_index()\n",
        "                    effective_count_per_class_full_train = original_counts_full_train.max()\n",
        "\n",
        "                    minority_class_indices = original_counts_full_train[original_counts_full_train < effective_count_per_class_full_train].index.tolist()\n",
        "                    minority_classes_df_for_display = full_train_df[full_train_df['label'].isin(minority_class_indices)].copy()\n",
        "                    minority_classes_df_for_display['class_name'] = minority_classes_df_for_display['label'].map(idx_to_classes)\n",
        "                print(\"\\u2714\\ufe0f `minority_classes_df_for_display` reloaded/reconstructed.\")\n",
        "\n",
        "            # Save the DataFrame to CSV\n",
        "            if not minority_classes_df_for_display.empty:\n",
        "                minority_classes_df_for_display[['path', 'class_name']].to_csv(csv_path, index=False)\n",
        "                print(f\"✔️ Successfully saved cGAN training data to '{csv_path}'.\")\n",
        "\n",
        "                # Git operations to add, commit, and push the CSV\n",
        "                print(\"Adding new CSV file to Git staging area...\")\n",
        "                !git add {csv_filename}\n",
        "\n",
        "                print(\"Committing changes...\")\n",
        "                # Ensure Git user is configured before committing (redundant but safe)\n",
        "                !git config user.name \"{GIT_USER_NAME}\"\n",
        "                !git config user.email \"{GIT_USER_EMAIL}\"\n",
        "                !git commit -m \"{commit_message}\"\n",
        "                print(\"✔️ Changes committed.\")\n",
        "\n",
        "                print(\"Pushing changes to GitHub...\")\n",
        "                !git push\n",
        "                print(\"✔️ Changes pushed to GitHub.\")\n",
        "            else:\n",
        "                print(\"ℹ️ No cGAN training data to save (DataFrame is empty).\")\n",
        "\n",
        "            # --- Return to original working directory ---\n",
        "            %cd /content/\n",
        "\n",
        "            print(\"\\n✅ Git operations complete.\")\n",
        "    else:\n",
        "        print(\"\\n❌ Git operations aborted due to missing configuration from Colab Secrets. Ensure 'repo', 'nameGit', 'email' are set.\")"
      ],
      "metadata": {
        "id": "sG5GcNkDdfaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Robustly ensure `full_train_df`, `original_counts_full_train`, `effective_count_per_class_full_train`, `all_classes`, and `idx_to_classes` are available ---\n",
        "# This block should only run if these variables are not already defined in the kernel.\n",
        "if 'full_train_df' not in globals() or 'original_counts_full_train' not in globals() or \\\n",
        "   'effective_count_per_class_full_train' not in globals() or 'all_classes' not in globals() or \\\n",
        "   'idx_to_classes' not in globals():\n",
        "    print(\"\\u26a0\\ufe0f Necessary data components not found. Attempting to reload data components.\")\n",
        "\n",
        "    data_root_dir = Path(\"/content/InfraredSolarModules\")\n",
        "    if not data_root_dir.exists() or not any(data_root_dir.iterdir()):\n",
        "        print(\"Downloading and extracting dataset...\")\n",
        "        !rm -rf /content/*\n",
        "        !wget -q -O /content/infrared.zip \\\n",
        "          \"https://github.com/RaptorMaps/InfraredSolarModules/raw/master/2020-02-14_InfraredSolarModules.zip\"\n",
        "        !unzip -q /content/infrared.zip -d /content/\n",
        "        print(\"Dataset downloaded and extracted.\")\n",
        "    else:\n",
        "        print(\"Dataset already present, skipping download and extraction.\")\n",
        "\n",
        "    data_dir = Path(\"/content/InfraredSolarModules\")\n",
        "    meta_path = data_dir / \"module_metadata.json\"\n",
        "    with open(meta_path, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    all_classes = sorted({info[\"anomaly_class\"] for info in metadata.values()})\n",
        "    classes_map = {cls: idx for idx, cls in enumerate(all_classes)}\n",
        "    idx_to_classes = {v: k for k, v in classes_map.items()}\n",
        "\n",
        "    rows = []\n",
        "    for img_id, info in metadata.items():\n",
        "        full_image_path = data_dir / info[\"image_filepath\"]\n",
        "        rows.append({\"img_id\": img_id, \"label\": info[\"anomaly_class\"], \"path\": str(full_image_path)})\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Re-perform initial train_test_split\n",
        "    full_train_df, _ = train_test_split(\n",
        "        df,\n",
        "        test_size=0.2,\n",
        "        stratify=df['label'],\n",
        "        random_state=42\n",
        "    )\n",
        "    full_train_df = full_train_df.reset_index(drop=True)\n",
        "    full_train_df['label'] = full_train_df['label'].map(classes_map)\n",
        "\n",
        "    # Re-calculate original_counts_full_train and effective_count_per_class_full_train\n",
        "    original_counts_full_train = full_train_df['label'].value_counts().sort_index()\n",
        "    effective_count_per_class_full_train = original_counts_full_train.max()\n",
        "\n",
        "    print(\"\\u2714\\ufe0f Data components reloaded/recalculated.\")\n",
        "\n",
        "# Identify the minority classes used for cGAN training\n",
        "minority_class_indices = original_counts_full_train[original_counts_full_train < effective_count_per_class_full_train].index.tolist()\n",
        "\n",
        "# Filter full_train_df to create minority_classes_df\n",
        "minority_classes_df_for_display = full_train_df[full_train_df['label'].isin(minority_class_indices)].copy()\n",
        "\n",
        "# Map integer labels back to human-readable class names for display\n",
        "minority_classes_df_for_display['class_name'] = minority_classes_df_for_display['label'].map(idx_to_classes)\n",
        "\n",
        "print(\"List of images and their classes used for cGAN training:\")\n",
        "display(minority_classes_df_for_display[['path', 'class_name']].head(10))\n",
        "print(f\"... and {len(minority_classes_df_for_display) - 10} more rows.\")\n",
        "print(f\"Total unique minority classes trained on: {len(minority_classes_df_for_display['class_name'].unique())}\")\n",
        "print(f\"Total images used for cGAN training: {len(minority_classes_df_for_display)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "8ZmpUbIifYSp",
        "outputId": "574d7dc8-3373-4bdc-a533-80333eb03906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of images and their classes used for cGAN training:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             path  class_name\n",
              "0   /content/InfraredSolarModules/images/9145.jpg  Vegetation\n",
              "1   /content/InfraredSolarModules/images/1178.jpg       Diode\n",
              "4   /content/InfraredSolarModules/images/3301.jpg   Shadowing\n",
              "5   /content/InfraredSolarModules/images/1120.jpg       Diode\n",
              "8   /content/InfraredSolarModules/images/1672.jpg       Diode\n",
              "9   /content/InfraredSolarModules/images/6786.jpg    Hot-Spot\n",
              "10  /content/InfraredSolarModules/images/6313.jpg        Cell\n",
              "11  /content/InfraredSolarModules/images/2718.jpg   Shadowing\n",
              "16  /content/InfraredSolarModules/images/9539.jpg  Vegetation\n",
              "18  /content/InfraredSolarModules/images/3971.jpg  Cell-Multi"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5295ccd6-9b45-4e3d-b8ef-2f626c8f9336\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/InfraredSolarModules/images/9145.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/InfraredSolarModules/images/1178.jpg</td>\n",
              "      <td>Diode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/InfraredSolarModules/images/3301.jpg</td>\n",
              "      <td>Shadowing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/InfraredSolarModules/images/1120.jpg</td>\n",
              "      <td>Diode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/InfraredSolarModules/images/1672.jpg</td>\n",
              "      <td>Diode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/content/InfraredSolarModules/images/6786.jpg</td>\n",
              "      <td>Hot-Spot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/content/InfraredSolarModules/images/6313.jpg</td>\n",
              "      <td>Cell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/content/InfraredSolarModules/images/2718.jpg</td>\n",
              "      <td>Shadowing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/content/InfraredSolarModules/images/9539.jpg</td>\n",
              "      <td>Vegetation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/content/InfraredSolarModules/images/3971.jpg</td>\n",
              "      <td>Cell-Multi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5295ccd6-9b45-4e3d-b8ef-2f626c8f9336')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5295ccd6-9b45-4e3d-b8ef-2f626c8f9336 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5295ccd6-9b45-4e3d-b8ef-2f626c8f9336');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3d6e29d7-59f6-4a91-9455-0862754b2c0e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d6e29d7-59f6-4a91-9455-0862754b2c0e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3d6e29d7-59f6-4a91-9455-0862754b2c0e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"Total images used for cGAN training: {len(minority_classes_df_for_display)}\\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"/content/InfraredSolarModules/images/9539.jpg\",\n          \"/content/InfraredSolarModules/images/1178.jpg\",\n          \"/content/InfraredSolarModules/images/6786.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Vegetation\",\n          \"Diode\",\n          \"Cell-Multi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... and 7990 more rows.\n",
            "Total unique minority classes trained on: 11\n",
            "Total images used for cGAN training: 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d6dc1d1"
      },
      "source": [
        "# Task\n",
        "Create a standard PyTorch `DataLoader` for the `balanced_train_df`, which is already perfectly balanced (8000 samples per class). Instantiate a `SolarDataset` using `balanced_train_df` and the existing `transform`, then create a `DataLoader` with `batch_size=32`, `shuffle=True`, and `num_workers=2`. Explicitly confirm that a `WeightedRandomSampler` is not needed due to the perfect class balance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac26994a"
      },
      "source": [
        "## Calculate Average Target Count\n",
        "\n",
        "### Subtask:\n",
        "Calculate the average number of samples per class across the *original* `train_df`. This average will be the exact target count for *every* class in the perfectly balanced dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2764f27b"
      },
      "source": [
        "**Reasoning**:\n",
        "To calculate the average number of samples per class, I will first ensure `train_df` is loaded, then get the value counts of the 'label' column, and finally compute and print their average.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a23e540",
        "outputId": "cb913c3b-3369-4a0a-d695-5040b288af9d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Calculating average samples per class...\")\n",
        "\n",
        "# 1. Ensure the `train_df` DataFrame is loaded and available.\n",
        "if 'train_df' not in globals():\n",
        "    print(\"⚠️ `train_df` not found. Attempting to reload from '/content/full_train_data_list.csv'.\")\n",
        "    train_df = pd.read_csv(\"/content/full_train_data_list.csv\")\n",
        "    # Re-map labels if necessary to ensure consistency with `classes_map`\n",
        "    if 'classes_map' in globals():\n",
        "        train_df['label'] = train_df['class_name'].map(classes_map)\n",
        "    print(\"✔️ `train_df` reloaded.\")\n",
        "else:\n",
        "    print(\"✔️ `train_df` is already loaded.\")\n",
        "\n",
        "# 2. Calculate the value counts for the 'label' column in `train_df`.\n",
        "original_class_counts = train_df['label'].value_counts().sort_index()\n",
        "\n",
        "# 3. Compute the average number of samples per class.\n",
        "# The total number of classes should be available from `num_classes` or `len(all_classes)`.\n",
        "if 'num_classes' not in globals():\n",
        "    if 'all_classes' in globals():\n",
        "        num_classes = len(all_classes)\n",
        "    else:\n",
        "        # Fallback if all_classes is not defined, infer from labels\n",
        "        num_classes = train_df['label'].nunique()\n",
        "    print(f\"⚠️ `num_classes` not found, inferred as {num_classes}.\")\n",
        "\n",
        "# Calculate average based on the existing classes in the original train_df to avoid issues if some classes are missing\n",
        "# from the split, though stratify should prevent this.\n",
        "# However, the task specifically asks for the average count for *every* class in the *perfectly balanced* dataset.\n",
        "# The prompt implies calculating it from the original train_df, but it's meant to be the target for *every* class.\n",
        "# A more robust interpretation is to take the max count as the target for *all* classes.\n",
        "# Re-reading: \"This average will be the exact target count for *every* class in the perfectly balanced dataset.\"\n",
        "# This implies that the total number of samples divided by the total number of classes.\n",
        "# This is consistent with how the existing `majority_class_count` was computed in previous cells.\n",
        "\n",
        "# To truly balance it perfectly to an average, we would sum all counts and divide by num_classes\n",
        "# However, the problem's current solution uses `majority_class_count = class_counts.max()` as the target.\n",
        "# I will follow the spirit of the instruction \"average number of samples per class across the *original* train_df\"\n",
        "# to calculate the target, but also acknowledge the previous approach of using `max()` for consistency.\n",
        "\n",
        "# Calculate the total number of samples and classes from the original train_df\n",
        "total_samples_in_original_train_df = len(train_df)\n",
        "num_classes_in_original_train_df = train_df['label'].nunique()\n",
        "\n",
        "# Calculate the average number of samples per class in the original train_df\n",
        "# This average will be the target count for *every* class in the perfectly balanced dataset, IF we aimed for average.\n",
        "# Given the previous steps where `majority_class_count = class_counts.max()` was used as target, I will compute both.\n",
        "\n",
        "average_count_per_class = total_samples_in_original_train_df / num_classes_in_original_train_df\n",
        "\n",
        "# For consistency with the existing balancing logic, it's more likely `majority_class_count` is the intended target.\n",
        "# However, I will output the direct average as requested by the subtask title.\n",
        "\n",
        "# 4. Print the original class distribution and the calculated `average_target_count`.\n",
        "print(\"\\nOriginal training class distribution:\")\n",
        "print(original_class_counts)\n",
        "\n",
        "print(f\"\\nCalculated average samples per class in original train_df: {average_count_per_class:.2f}\")\n",
        "print(f\"(Note: In previous steps, the maximum class count ({original_class_counts.max()}) was used as the target for balancing.)\")\n",
        "\n",
        "# Store the average as `average_target_count` as requested.\n",
        "average_target_count = average_count_per_class\n",
        "print(\"✔️ Average target count calculated.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating average samples per class...\n",
            "✔️ `train_df` is already loaded.\n",
            "\n",
            "Original training class distribution:\n",
            "label\n",
            "0     1502\n",
            "1     1030\n",
            "2      752\n",
            "3     1199\n",
            "4      140\n",
            "5      199\n",
            "6      197\n",
            "7     8000\n",
            "8      662\n",
            "9      845\n",
            "10     163\n",
            "11    1311\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Calculated average samples per class in original train_df: 1333.33\n",
            "(Note: In previous steps, the maximum class count (8000) was used as the target for balancing.)\n",
            "✔️ Average target count calculated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b165bd7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to create a standard PyTorch DataLoader for the perfectly balanced `balanced_train_df`, explicitly stating that a `WeightedRandomSampler` is not required due to the balanced nature of the dataset. This involves instantiating `SolarDataset` and then a `DataLoader` with shuffling enabled.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cccdd00",
        "outputId": "565ceea4-c9fe-4eaa-875a-2843cc4d86d2"
      },
      "source": [
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image # Ensure Image is imported for SolarDataset\n",
        "\n",
        "print(\"Creating a standard DataLoader for the perfectly balanced training data...\")\n",
        "\n",
        "# Define image transformations for the dataset (copied from previous cells where it was defined)\n",
        "# Ensure `transform` is available. It was defined in cell j3lovn9RFwOD and new_conditional_generator_definition.\n",
        "if 'transform' not in globals():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)), # Resize images to 64x64\n",
        "        transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "        transforms.Normalize(\n",
        "            mean=(0.5,),             # Normalize for 1-channel image (grayscale)\n",
        "            std=(0.5,)\n",
        "        )\n",
        "    ])\n",
        "    print(\"⚠️ `transform` pipeline not found, re-defined.\")\n",
        "else:\n",
        "    print(\"✔️ `transform` pipeline is already defined.\")\n",
        "\n",
        "# Ensure SolarDataset class is available (it was defined in cell j3lovn9RFwOD and new_conditional_generator_definition)\n",
        "if 'SolarDataset' not in globals():\n",
        "    class SolarDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, df, transform=None):\n",
        "            self.df = df.reset_index(drop=True)\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.df)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            row = self.df.iloc[idx]\n",
        "            image = Image.open(row[\"path\"]).convert(\"L\") # Open image and convert to grayscale\n",
        "            label = row[\"label\"]\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "    print(\"⚠️ `SolarDataset` class not found, re-defined.\")\n",
        "else:\n",
        "    print(\"✔️ `SolarDataset` class is already defined.\")\n",
        "\n",
        "# 1. Instantiate SolarDataset for the balanced training data\n",
        "balanced_train_dataset_standard = SolarDataset(balanced_train_df, transform=transform)\n",
        "print(\"✔️ `balanced_train_dataset_standard` created.\")\n",
        "\n",
        "# 2. Define batch size and number of workers\n",
        "# `batch_size` and `num_workers` are assumed to be defined from previous cells (e.g., j3lovn9RFwOD).\n",
        "# If not, default values will be used.\n",
        "if 'batch_size' not in globals():\n",
        "    batch_size = 32\n",
        "    print(f\"⚠️ `batch_size` not found, defaulting to {batch_size}.\")\n",
        "if 'num_workers' not in globals():\n",
        "    num_workers = 2\n",
        "    print(f\"⚠️ `num_workers` not found, defaulting to {num_workers}.\")\n",
        "\n",
        "# 3. Create a standard DataLoader with shuffle=True\n",
        "balanced_train_loader_standard = torch.utils.data.DataLoader(\n",
        "    balanced_train_dataset_standard,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,             # Shuffle the data as it's already balanced\n",
        "    num_workers=num_workers\n",
        ")\n",
        "print(\"✔️ Standard `balanced_train_loader` created with shuffling.\")\n",
        "\n",
        "# 4. Confirm that WeightedRandomSampler is not needed\n",
        "print(\"\\nConfirmation: A `WeightedRandomSampler` is NOT needed for `balanced_train_loader_standard` because the `balanced_train_df` is already perfectly balanced, with each class containing an equal number of samples. Standard shuffling is sufficient for unbiased sampling.\")\n",
        "\n",
        "print(f\"Number of batches in balanced_train_loader_standard: {len(balanced_train_loader_standard)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a standard DataLoader for the perfectly balanced training data...\n",
            "✔️ `transform` pipeline is already defined.\n",
            "✔️ `SolarDataset` class is already defined.\n",
            "✔️ `balanced_train_dataset_standard` created.\n",
            "✔️ Standard `balanced_train_loader` created with shuffling.\n",
            "\n",
            "Confirmation: A `WeightedRandomSampler` is NOT needed for `balanced_train_loader_standard` because the `balanced_train_df` is already perfectly balanced, with each class containing an equal number of samples. Standard shuffling is sufficient for unbiased sampling.\n",
            "Number of batches in balanced_train_loader_standard: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffdce0cd"
      },
      "source": [
        "## Prepare Data for Over/Undersampling\n",
        "\n",
        "### Subtask:\n",
        "Categorize each class in the original `train_df` based on whether its count is below, equal to, or above the calculated average target. This will guide which samples need GAN generation and which need random undersampling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "594f45c5"
      },
      "source": [
        "**Reasoning**:\n",
        "To categorize each class, I will first ensure `train_df` and `average_target_count` are available, then iterate through the original class counts and compare them against `average_target_count` to determine if each class needs oversampling, undersampling, or is already balanced, storing the results and printing a summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d54443d0",
        "outputId": "a46744a8-71d2-49c4-c5a0-17e968b7ef1c"
      },
      "source": [
        "print(\"Categorizing classes based on average target count...\")\n",
        "\n",
        "# 1. Ensure `train_df` DataFrame and `average_target_count` are available.\n",
        "# `train_df` is expected to be loaded from previous cells.\n",
        "# `average_target_count` is expected to be calculated from the previous step.\n",
        "if 'train_df' not in globals():\n",
        "    print(\"⚠️ `train_df` not found. Attempting to reload from '/content/full_train_data_list.csv'.\")\n",
        "    train_df = pd.read_csv(\"/content/full_train_data_list.csv\")\n",
        "    if 'classes_map' in globals():\n",
        "        train_df['label'] = train_df['class_name'].map(classes_map)\n",
        "    print(\"✔️ `train_df` reloaded.\")\n",
        "\n",
        "if 'average_target_count' not in globals():\n",
        "    raise RuntimeError(\"Error: `average_target_count` not found. Please ensure the previous step to calculate it was executed.\")\n",
        "\n",
        "print(f\"Average target count for balancing: {average_target_count:.2f}\")\n",
        "\n",
        "# 2. Get the value counts of the 'label' column from `train_df`.\n",
        "original_class_counts = train_df['label'].value_counts().sort_index()\n",
        "print(\"\\nOriginal training class distribution:\")\n",
        "print(original_class_counts)\n",
        "\n",
        "# 3. Initialize dictionaries to store categorized classes.\n",
        "oversample_classes = {}\n",
        "undersample_classes = {}\n",
        "balanced_classes = {}\n",
        "\n",
        "# 4. Iterate through each class and its count in the original class distribution:\n",
        "for class_label, count in original_class_counts.items():\n",
        "    class_name = idx_to_classes.get(class_label, f\"Label {class_label}\") # Use idx_to_classes for readability\n",
        "    if count < average_target_count:\n",
        "        needed_for_oversample = int(average_target_count - count)\n",
        "        oversample_classes[class_name] = {\"original_count\": count, \"needed\": needed_for_oversample}\n",
        "    elif count > average_target_count:\n",
        "        to_retain_for_undersample = int(average_target_count)\n",
        "        undersample_classes[class_name] = {\"original_count\": count, \"retain\": to_retain_for_undersample}\n",
        "    else:\n",
        "        balanced_classes[class_name] = {\"original_count\": count}\n",
        "\n",
        "# 5. Print a summary of the categorized classes and their respective target actions.\n",
        "print(\"\\n--- Class Categorization Summary ---\")\n",
        "if oversample_classes:\n",
        "    print(\"Classes to Oversample (GAN Generation Needed):\")\n",
        "    for cls, info in oversample_classes.items():\n",
        "        print(f\"  - {cls}: Original={info['original_count']}, Need={info['needed']} synthetic samples\")\n",
        "else:\n",
        "    print(\"No classes require oversampling.\")\n",
        "\n",
        "if undersample_classes:\n",
        "    print(\"\\nClasses to Undersample (Random Undersampling Needed):\")\n",
        "    for cls, info in undersample_classes.items():\n",
        "        print(f\"  - {cls}: Original={info['original_count']}, Retain={info['retain']} samples\")\n",
        "else:\n",
        "    print(\"No classes require undersampling.\")\n",
        "\n",
        "if balanced_classes:\n",
        "    print(\"\\nClasses Already Balanced:\")\n",
        "    for cls, info in balanced_classes.items():\n",
        "        print(f\"  - {cls}: Original={info['original_count']} samples\")\n",
        "else:\n",
        "    print(\"No classes are perfectly balanced to the average target.\")\n",
        "\n",
        "print(\"\\n✔️ Classes categorized successfully.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorizing classes based on average target count...\n",
            "Average target count for balancing: 1333.33\n",
            "\n",
            "Original training class distribution:\n",
            "label\n",
            "0     1502\n",
            "1     1030\n",
            "2      752\n",
            "3     1199\n",
            "4      140\n",
            "5      199\n",
            "6      197\n",
            "7     8000\n",
            "8      662\n",
            "9      845\n",
            "10     163\n",
            "11    1311\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Class Categorization Summary ---\n",
            "Classes to Oversample (GAN Generation Needed):\n",
            "  - Cell-Multi: Original=1030, Need=303 synthetic samples\n",
            "  - Cracking: Original=752, Need=581 synthetic samples\n",
            "  - Diode: Original=1199, Need=134 synthetic samples\n",
            "  - Diode-Multi: Original=140, Need=1193 synthetic samples\n",
            "  - Hot-Spot: Original=199, Need=1134 synthetic samples\n",
            "  - Hot-Spot-Multi: Original=197, Need=1136 synthetic samples\n",
            "  - Offline-Module: Original=662, Need=671 synthetic samples\n",
            "  - Shadowing: Original=845, Need=488 synthetic samples\n",
            "  - Soiling: Original=163, Need=1170 synthetic samples\n",
            "  - Vegetation: Original=1311, Need=22 synthetic samples\n",
            "\n",
            "Classes to Undersample (Random Undersampling Needed):\n",
            "  - Cell: Original=1502, Retain=1333 samples\n",
            "  - No-Anomaly: Original=8000, Retain=1333 samples\n",
            "No classes are perfectly balanced to the average target.\n",
            "\n",
            "✔️ Classes categorized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88f8e67c"
      },
      "source": [
        "## Undersample Over-Represented Classes\n",
        "\n",
        "### Subtask:\n",
        "For classes whose original count in `train_df` is greater than the calculated average, perform random undersampling. Randomly select and retain *exactly* the number of samples from these classes needed to reduce their count to the average target. Store these selected original samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264e11b5"
      },
      "source": [
        "**Reasoning**:\n",
        "To perform random undersampling, I will iterate through the `undersample_classes` dictionary, filter `train_df` for each class, randomly sample the required number of instances, and store them. Finally, I will combine all retained samples into a single DataFrame and display its head and class distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "c81d4219",
        "outputId": "ebd42943-0eaf-4e92-d984-a77ffe857be5"
      },
      "source": [
        "print(\"Performing random undersampling for over-represented classes...\")\n",
        "\n",
        "# 1. Initialize an empty list to store the original samples that will be retained\n",
        "retained_samples_list = []\n",
        "\n",
        "# 2. Iterate through the undersample_classes dictionary.\n",
        "for class_name, info in undersample_classes.items():\n",
        "    # Get the numerical label from class_name\n",
        "    # First, invert idx_to_classes to get class_name to label mapping\n",
        "    name_to_idx = {name: idx for idx, name in idx_to_classes.items()}\n",
        "    class_label = name_to_idx.get(class_name)\n",
        "\n",
        "    if class_label is None:\n",
        "        print(f\"Warning: Class name '{class_name}' not found in idx_to_classes. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Undersampling class '{class_name}' (label {class_label})...\")\n",
        "\n",
        "    # a. Filter the train_df to get all samples belonging to the current class.\n",
        "    class_samples = train_df[train_df['label'] == class_label]\n",
        "\n",
        "    # b. Randomly sample 'retain' number of rows from these class-specific samples.\n",
        "    # Ensure that we don't try to sample more than available, although 'retain' should be <= original_count\n",
        "    retain_count = info['retain']\n",
        "    if retain_count > len(class_samples):\n",
        "        print(f\"Warning: Requested to retain {retain_count} samples for class {class_name}, but only {len(class_samples)} available. Retaining all available.\")\n",
        "        sampled_class_samples = class_samples\n",
        "    else:\n",
        "        sampled_class_samples = class_samples.sample(n=retain_count, random_state=42)\n",
        "\n",
        "    # c. Append these randomly selected samples to the list\n",
        "    retained_samples_list.append(sampled_class_samples)\n",
        "    print(f\"  Retained {len(sampled_class_samples)} samples for class '{class_name}'.\")\n",
        "\n",
        "# 3. Concatenate the stored samples into a single DataFrame.\n",
        "if retained_samples_list:\n",
        "    undersampled_original_df = pd.concat(retained_samples_list, ignore_index=True)\n",
        "    print(\"✔️ Undersampled original DataFrame created.\")\n",
        "else:\n",
        "    undersampled_original_df = pd.DataFrame(columns=train_df.columns) # Create an empty DataFrame with the correct columns\n",
        "    print(\"No classes required undersampling, created an empty undersampled_original_df.\")\n",
        "\n",
        "# 4. Display the head of undersampled_original_df and print its class distribution.\n",
        "print(\"\\nHead of the undersampled_original_df:\")\n",
        "display(undersampled_original_df.head())\n",
        "\n",
        "print(\"\\nClass distribution in undersampled_original_df:\")\n",
        "print(undersampled_original_df['label'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\n✔️ Random undersampling complete.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing random undersampling for over-represented classes...\n",
            "Undersampling class 'Cell' (label 0)...\n",
            "  Retained 1333 samples for class 'Cell'.\n",
            "Undersampling class 'No-Anomaly' (label 7)...\n",
            "  Retained 1333 samples for class 'No-Anomaly'.\n",
            "✔️ Undersampled original DataFrame created.\n",
            "\n",
            "Head of the undersampled_original_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  class_name  label                                           path\n",
              "0       Cell      0  /content/InfraredSolarModules/images/6337.jpg\n",
              "1       Cell      0  /content/InfraredSolarModules/images/6595.jpg\n",
              "2       Cell      0  /content/InfraredSolarModules/images/5863.jpg\n",
              "3       Cell      0  /content/InfraredSolarModules/images/5285.jpg\n",
              "4       Cell      0  /content/InfraredSolarModules/images/5026.jpg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eccfff31-81f3-4480-bd68-95e0a7e87d35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cell</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/InfraredSolarModules/images/6337.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cell</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/InfraredSolarModules/images/6595.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cell</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/InfraredSolarModules/images/5863.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cell</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/InfraredSolarModules/images/5285.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cell</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/InfraredSolarModules/images/5026.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eccfff31-81f3-4480-bd68-95e0a7e87d35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eccfff31-81f3-4480-bd68-95e0a7e87d35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eccfff31-81f3-4480-bd68-95e0a7e87d35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ba1aadd7-6739-4f22-b327-5f89f10b0b06\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba1aadd7-6739-4f22-b327-5f89f10b0b06')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ba1aadd7-6739-4f22-b327-5f89f10b0b06 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2714\\ufe0f Random undersampling complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Cell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/InfraredSolarModules/images/6595.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution in undersampled_original_df:\n",
            "label\n",
            "0    1333\n",
            "7    1333\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✔️ Random undersampling complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dc51126"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that undersampling for over-represented classes is complete, the next step is to generate synthetic images for the under-represented classes (oversampling) using the loaded GAN generator, based on the `oversample_classes` dictionary. These generated images will be stored in a temporary directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "723f3618",
        "outputId": "75a9ebf6-4cca-4596-9f32-1211a5db5f75"
      },
      "source": [
        "print(\"Generating synthetic images for under-represented classes...\")\n",
        "\n",
        "# --- 1. Create a temporary directory for synthetic images if it doesn't exist ---\n",
        "synthetic_images_dir_for_oversampling = Path(\"/content/synthetic_images_oversampling\")\n",
        "synthetic_images_dir_for_oversampling.mkdir(exist_ok=True)\n",
        "print(f\"Created temporary directory for oversampling: {synthetic_images_dir_for_oversampling}\")\n",
        "\n",
        "# --- 2. Ensure the generator model is in evaluation mode ---\n",
        "# The generator was already loaded and set to eval() in a previous cell (35d93106).\n",
        "# This is a redundant check but ensures robustness.\n",
        "if 'generator' not in globals():\n",
        "    raise RuntimeError(\"Error: Generator model not found. Please ensure the GAN generator loading cell was executed.\")\n",
        "generator.eval()\n",
        "print(\"Generator is in evaluation mode.\")\n",
        "\n",
        "# --- 3. Initialize an empty list to store metadata for newly generated images ---\n",
        "synthetic_oversample_data_rows = []\n",
        "total_oversampled_generated_images = 0\n",
        "\n",
        "# --- 4. Iterate through classes to oversample and generate images ---\n",
        "for class_name, info in oversample_classes.items():\n",
        "    # Get the numerical label from class_name\n",
        "    name_to_idx = {name: idx for idx, name in idx_to_classes.items()}\n",
        "    class_label = name_to_idx.get(class_name)\n",
        "\n",
        "    if class_label is None:\n",
        "        print(f\"Warning: Class name '{class_name}' not found in idx_to_classes. Skipping oversampling.\")\n",
        "        continue\n",
        "\n",
        "    num_to_generate = info['needed']\n",
        "    if num_to_generate <= 0:\n",
        "        print(f\"Class '{class_name}' (label {class_label}) does not need synthetic images. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Generating {num_to_generate} images for class '{class_name}' (label {class_label})...\")\n",
        "\n",
        "    # --- 4.1. Generate images in batches ---\n",
        "    # Using batch_size_gen defined in previous GAN generation steps (defaults to 64).\n",
        "    if 'batch_size_gen' not in globals():\n",
        "        batch_size_gen = 64 # Default if not found\n",
        "\n",
        "    num_batches = (num_to_generate + batch_size_gen - 1) // batch_size_gen\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        current_batch_size = min(batch_size_gen, num_to_generate - (i * batch_size_gen))\n",
        "        if current_batch_size <= 0:\n",
        "            break\n",
        "\n",
        "        # a. Generate noise and labels for the current batch\n",
        "        noise = torch.randn(current_batch_size, z_dim, 1, 1, device=DEVICE)\n",
        "        labels = torch.full((current_batch_size,), class_label, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "        # b. Pass to generator within no_grad context\n",
        "        with torch.no_grad():\n",
        "            synthetic_images = generator(noise, labels).cpu() # Move to CPU for saving\n",
        "\n",
        "        # c. Save generated images and collect metadata\n",
        "        for j in range(current_batch_size):\n",
        "            img_tensor = synthetic_images[j]\n",
        "            # De-normalize and convert to PIL Image\n",
        "            img = transforms.ToPILImage()(img_tensor.squeeze(0).mul(0.5).add(0.5))\n",
        "\n",
        "            # Construct unique filename\n",
        "            img_filename = synthetic_images_dir_for_oversampling / f\"synthetic_oversample_{class_name}_{total_oversampled_generated_images}.png\"\n",
        "            img.save(img_filename)\n",
        "\n",
        "            # Append metadata\n",
        "            synthetic_oversample_data_rows.append({\n",
        "                \"path\": str(img_filename),\n",
        "                \"class_name\": class_name,\n",
        "                \"label\": class_label\n",
        "            })\n",
        "            total_oversampled_generated_images += 1\n",
        "    print(f\"  Generated {num_to_generate} images for class '{class_name}'.\")\n",
        "\n",
        "# --- 5. Convert metadata to a pandas DataFrame ---\n",
        "synthetic_oversample_df = pd.DataFrame(synthetic_oversample_data_rows)\n",
        "\n",
        "# --- 6. Print summary ---\n",
        "print(f\"\\n✔️ Generated a total of {total_oversampled_generated_images} synthetic images for oversampling.\")\n",
        "print(\"Synthetic oversample data distribution:\\n\", synthetic_oversample_df['label'].value_counts().sort_index())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic images for under-represented classes...\n",
            "Created temporary directory for oversampling: /content/synthetic_images_oversampling\n",
            "Generator is in evaluation mode.\n",
            "Generating 303 images for class 'Cell-Multi' (label 1)...\n",
            "  Generated 303 images for class 'Cell-Multi'.\n",
            "Generating 581 images for class 'Cracking' (label 2)...\n",
            "  Generated 581 images for class 'Cracking'.\n",
            "Generating 134 images for class 'Diode' (label 3)...\n",
            "  Generated 134 images for class 'Diode'.\n",
            "Generating 1193 images for class 'Diode-Multi' (label 4)...\n",
            "  Generated 1193 images for class 'Diode-Multi'.\n",
            "Generating 1134 images for class 'Hot-Spot' (label 5)...\n",
            "  Generated 1134 images for class 'Hot-Spot'.\n",
            "Generating 1136 images for class 'Hot-Spot-Multi' (label 6)...\n",
            "  Generated 1136 images for class 'Hot-Spot-Multi'.\n",
            "Generating 671 images for class 'Offline-Module' (label 8)...\n",
            "  Generated 671 images for class 'Offline-Module'.\n",
            "Generating 488 images for class 'Shadowing' (label 9)...\n",
            "  Generated 488 images for class 'Shadowing'.\n",
            "Generating 1170 images for class 'Soiling' (label 10)...\n",
            "  Generated 1170 images for class 'Soiling'.\n",
            "Generating 22 images for class 'Vegetation' (label 11)...\n",
            "  Generated 22 images for class 'Vegetation'.\n",
            "\n",
            "✔️ Generated a total of 6832 synthetic images for oversampling.\n",
            "Synthetic oversample data distribution:\n",
            " label\n",
            "1      303\n",
            "2      581\n",
            "3      134\n",
            "4     1193\n",
            "5     1134\n",
            "6     1136\n",
            "8      671\n",
            "9      488\n",
            "10    1170\n",
            "11      22\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2cdd224"
      },
      "source": [
        "**Reasoning**:\n",
        "To achieve the final balanced dataset, I will first identify the original samples from `train_df` that belong to classes already balanced or that were not over/undersampled. Then, I will concatenate these original samples with the `undersampled_original_df` (from over-represented classes) and the `synthetic_oversample_df` (from under-represented classes) to form a new `balanced_train_df_new`. Finally, I will shuffle this new DataFrame and display its head and class distribution to verify the balancing using the average target count.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "85d499e2",
        "outputId": "a490fa0e-da00-42d2-bb15-1ff1c61edacc"
      },
      "source": [
        "print(\"Combining all data sources to create the final balanced training DataFrame...\")\n",
        "\n",
        "# 1. Identify classes that were not undersampled or oversampled and retain their original samples\n",
        "# These are the classes that had counts equal to 'average_target_count' in the original train_df,\n",
        "# or classes whose undersampling/oversampling was handled completely by the previous steps.\n",
        "# Since we're rebuilding the balanced_train_df based on average_target_count, we need to select\n",
        "# 'average_target_count' samples from each original class if it wasn't handled by undersampling.\n",
        "\n",
        "# First, identify which classes need to be fully drawn from the original train_df (those not in undersample_classes)\n",
        "# This includes classes that were initially less than or equal to the average, but not requiring GAN generation\n",
        "# or those that were just below the average and have now been filled by GAN.\n",
        "\n",
        "# Get numerical labels for oversample_classes and undersample_classes\n",
        "name_to_idx = {name: idx for idx, name in idx_to_classes.items()}\n",
        "oversample_labels = {name_to_idx[cls] for cls in oversample_classes.keys() if cls in name_to_idx}\n",
        "undersample_labels = {name_to_idx[cls] for cls in undersample_classes.keys() if cls in name_to_idx}\n",
        "\n",
        "# Identify classes whose original samples were not part of undersampling, and were not oversampled either.\n",
        "# These are classes that might have been exactly at the average, or will be made up entirely of generated images for now.\n",
        "# For a correct combined `balanced_train_df_new`, we must ensure that each class contains `int(average_target_count)` samples.\n",
        "\n",
        "all_balanced_data_rows = []\n",
        "\n",
        "# Add samples from undersampled_original_df\n",
        "if not undersampled_original_df.empty:\n",
        "    all_balanced_data_rows.append(undersampled_original_df)\n",
        "    print(\"✔️ Added undersampled original data.\")\n",
        "\n",
        "# Add samples from synthetic_oversample_df\n",
        "if not synthetic_oversample_df.empty:\n",
        "    all_balanced_data_rows.append(synthetic_oversample_df)\n",
        "    print(\"✔️ Added synthetic oversample data.\")\n",
        "\n",
        "# Handle classes that were not part of oversampling or undersampling and need their 'average_target_count' samples\n",
        "# or classes that were originally over the average but were undersampled, we already added them.\n",
        "# For classes that were originally below average and were oversampled, we already added them.\n",
        "# What remains are classes that were originally equal to the average, or if the average_target_count approach needs\n",
        "# to trim/fill any specific class. The goal is `int(average_target_count)` for *each* class.\n",
        "\n",
        "# Let's iterate through all original classes to ensure each ends up with `int(average_target_count)` samples.\n",
        "# This means we might need to take `int(average_target_count)` from `train_df` for classes not affected by GAN or undersampling.\n",
        "\n",
        "for class_label in range(num_classes):\n",
        "    if class_label not in oversample_labels and class_label not in undersample_labels:\n",
        "        # This class was neither oversampled nor undersampled. It should be close to the average.\n",
        "        # We need to take `int(average_target_count)` samples from the original `train_df` for this class.\n",
        "        class_samples = train_df[train_df['label'] == class_label]\n",
        "        retain_count = int(average_target_count)\n",
        "\n",
        "        if retain_count > len(class_samples):\n",
        "            print(f\"Warning: Class '{idx_to_classes[class_label]}' (label {class_label}) originally had {len(class_samples)} samples, but target is {retain_count}. Taking all original samples.\")\n",
        "            retained_original_class_samples = class_samples\n",
        "        else:\n",
        "            retained_original_class_samples = class_samples.sample(n=retain_count, random_state=42)\n",
        "\n",
        "        all_balanced_data_rows.append(retained_original_class_samples)\n",
        "        print(f\"✔️ Added {len(retained_original_class_samples)} original samples for class '{idx_to_classes[class_label]}'.\")\n",
        "\n",
        "# 2. Concatenate all stored samples into a single DataFrame.\n",
        "if all_balanced_data_rows:\n",
        "    balanced_train_df_new = pd.concat(all_balanced_data_rows, ignore_index=True)\n",
        "    print(\"✔️ Final balanced training DataFrame created.\")\n",
        "else:\n",
        "    balanced_train_df_new = pd.DataFrame(columns=train_df.columns)\n",
        "    print(\"No data to concatenate, created an empty balanced_train_df_new.\")\n",
        "\n",
        "# 3. Shuffle the balanced_train_df_new.\n",
        "balanced_train_df_new = balanced_train_df_new.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"✔️ Final balanced training DataFrame shuffled and index reset.\")\n",
        "\n",
        "# 4. Display the head of the balanced_train_df_new and print its class distribution.\n",
        "print(\"\\nHead of the balanced_train_df_new:\")\n",
        "display(balanced_train_df_new.head())\n",
        "\n",
        "print(\"\\nClass distribution in balanced_train_df_new:\")\n",
        "print(balanced_train_df_new['label'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\n✔️ Data balancing using average target count complete.\")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining all data sources to create the final balanced training DataFrame...\n",
            "✔️ Added undersampled original data.\n",
            "✔️ Added synthetic oversample data.\n",
            "✔️ Final balanced training DataFrame created.\n",
            "✔️ Final balanced training DataFrame shuffled and index reset.\n",
            "\n",
            "Head of the balanced_train_df_new:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       class_name  label                                               path\n",
              "0  Offline-Module      8  /content/synthetic_images_oversampling/synthet...\n",
              "1  Hot-Spot-Multi      6  /content/synthetic_images_oversampling/synthet...\n",
              "2        Hot-Spot      5  /content/synthetic_images_oversampling/synthet...\n",
              "3      Cell-Multi      1  /content/synthetic_images_oversampling/synthet...\n",
              "4  Hot-Spot-Multi      6  /content/synthetic_images_oversampling/synthet..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9c5d7d2-94d2-4fbc-bda9-b3473dfaee0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Offline-Module</td>\n",
              "      <td>8</td>\n",
              "      <td>/content/synthetic_images_oversampling/synthet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hot-Spot-Multi</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/synthetic_images_oversampling/synthet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hot-Spot</td>\n",
              "      <td>5</td>\n",
              "      <td>/content/synthetic_images_oversampling/synthet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cell-Multi</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/synthetic_images_oversampling/synthet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hot-Spot-Multi</td>\n",
              "      <td>6</td>\n",
              "      <td>/content/synthetic_images_oversampling/synthet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9c5d7d2-94d2-4fbc-bda9-b3473dfaee0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9c5d7d2-94d2-4fbc-bda9-b3473dfaee0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9c5d7d2-94d2-4fbc-bda9-b3473dfaee0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75c1a7e5-991f-48df-93e1-77ba3cb6235b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75c1a7e5-991f-48df-93e1-77ba3cb6235b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75c1a7e5-991f-48df-93e1-77ba3cb6235b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2714\\ufe0f Data balancing using average target count complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hot-Spot-Multi\",\n          \"Cell-Multi\",\n          \"Offline-Module\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          1,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/synthetic_images_oversampling/synthetic_oversample_Hot-Spot-Multi_4190.png\",\n          \"/content/synthetic_images_oversampling/synthetic_oversample_Hot-Spot-Multi_4170.png\",\n          \"/content/synthetic_images_oversampling/synthetic_oversample_Hot-Spot_2446.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution in balanced_train_df_new:\n",
            "label\n",
            "0     1333\n",
            "1      303\n",
            "2      581\n",
            "3      134\n",
            "4     1193\n",
            "5     1134\n",
            "6     1136\n",
            "7     1333\n",
            "8      671\n",
            "9      488\n",
            "10    1170\n",
            "11      22\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✔️ Data balancing using average target count complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8468862"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed to produce a truly balanced dataset, as seen in the class distribution. The new `balanced_train_df_new` still contains varying counts per class. To correctly balance the dataset to `int(average_target_count)` for *every* class, I need to rebuild the `balanced_train_df_new` by iterating through each class and either undersampling original samples or generating synthetic samples to reach the `average_target_count`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "60600765",
        "outputId": "53dc3200-5e92-415a-e9fa-615fc00c8f8b"
      },
      "source": [
        "print(\"Reconstructing the final balanced training DataFrame based on average target count...\")\n",
        "\n",
        "# Ensure generator is in evaluation mode\n",
        "generator.eval()\n",
        "\n",
        "# Initialize an empty list to collect all samples (original and synthetic) for the final balanced DataFrame\n",
        "final_balanced_data_rows = []\n",
        "\n",
        "# Get numerical labels for convenience\n",
        "name_to_idx = {name: idx for idx, name in idx_to_classes.items()}\n",
        "\n",
        "# Determine the target count for each class, which is the integer part of average_target_count\n",
        "target_count_per_class = int(average_target_count)\n",
        "\n",
        "print(f\"Target count for each class: {target_count_per_class}\")\n",
        "\n",
        "# Iterate through each class to ensure it meets the target_count_per_class\n",
        "for class_label in range(num_classes):\n",
        "    class_name = idx_to_classes.get(class_label, f\"Label {class_label}\")\n",
        "    original_class_samples = train_df[train_df['label'] == class_label]\n",
        "    current_original_count = len(original_class_samples)\n",
        "\n",
        "    print(f\"Processing class '{class_name}' (label {class_label}): original count {current_original_count}\")\n",
        "\n",
        "    # Case 1: Class needs to be undersampled (original count > target count)\n",
        "    if current_original_count > target_count_per_class:\n",
        "        # Randomly sample `target_count_per_class` samples from the original data\n",
        "        retained_samples = original_class_samples.sample(n=target_count_per_class, random_state=42)\n",
        "        final_balanced_data_rows.append(retained_samples)\n",
        "        print(f\"  Undersampled: Retained {len(retained_samples)} original samples.\")\n",
        "\n",
        "    # Case 2: Class needs to be oversampled (original count <= target count)\n",
        "    elif current_original_count < target_count_per_class:\n",
        "        # Add all original samples\n",
        "        final_balanced_data_rows.append(original_class_samples)\n",
        "        print(f\"  Oversampling: Added {current_original_count} original samples.\")\n",
        "\n",
        "        # Generate synthetic images to make up the difference\n",
        "        needed_synthetic_count = target_count_per_class - current_original_count\n",
        "        if needed_synthetic_count > 0:\n",
        "            print(f\"  Oversampling: Generating {needed_synthetic_count} synthetic samples...\")\n",
        "\n",
        "            synthetic_data_for_class = []\n",
        "            batch_size_gen = 64 # Re-use or define batch size for generation\n",
        "            num_batches = (needed_synthetic_count + batch_size_gen - 1) // batch_size_gen\n",
        "\n",
        "            for i in range(num_batches):\n",
        "                current_batch_size = min(batch_size_gen, needed_synthetic_count - (i * batch_size_gen))\n",
        "                if current_batch_size <= 0:\n",
        "                    break\n",
        "\n",
        "                noise = torch.randn(current_batch_size, z_dim, 1, 1, device=DEVICE)\n",
        "                labels = torch.full((current_batch_size,), class_label, dtype=torch.long, device=DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    synthetic_images = generator(noise, labels).cpu()\n",
        "\n",
        "                for j in range(current_batch_size):\n",
        "                    img_tensor = synthetic_images[j]\n",
        "                    img = transforms.ToPILImage()(img_tensor.squeeze(0).mul(0.5).add(0.5))\n",
        "\n",
        "                    # Create a dummy path for the synthetic image. Actual saving is not strictly required for df creation.\n",
        "                    # For consistency with previous steps, we will use a structure similar to synthetic_images_oversampling.\n",
        "                    synthetic_oversample_dir = Path(\"/content/synthetic_images_final_balanced\")\n",
        "                    synthetic_oversample_dir.mkdir(exist_ok=True)\n",
        "                    img_filename = synthetic_oversample_dir / f\"synthetic_final_{class_name}_{len(synthetic_data_for_class)}.png\"\n",
        "                    img.save(img_filename) # Save the image temporarily\n",
        "\n",
        "                    synthetic_data_for_class.append({\n",
        "                        \"path\": str(img_filename),\n",
        "                        \"class_name\": class_name,\n",
        "                        \"label\": class_label\n",
        "                    })\n",
        "            if synthetic_data_for_class:\n",
        "                final_balanced_data_rows.append(pd.DataFrame(synthetic_data_for_class))\n",
        "            print(f\"  Oversampling: Generated {len(synthetic_data_for_class)} synthetic samples.\")\n",
        "\n",
        "    # Case 3: Class is already at target count (should be rare due to float average_target_count)\n",
        "    else:\n",
        "        final_balanced_data_rows.append(original_class_samples)\n",
        "        print(f\"  Already balanced: Added {current_original_count} original samples.\")\n",
        "\n",
        "# Concatenate all stored samples into a single DataFrame.\n",
        "if final_balanced_data_rows:\n",
        "    balanced_train_df_new = pd.concat(final_balanced_data_rows, ignore_index=True)\n",
        "    print(\"✔️ Final balanced training DataFrame created.\")\n",
        "else:\n",
        "    balanced_train_df_new = pd.DataFrame(columns=train_df.columns)\n",
        "    print(\"No data to concatenate, created an empty balanced_train_df_new.\")\n",
        "\n",
        "# Shuffle the balanced_train_df_new.\n",
        "balanced_train_df_new = balanced_train_df_new.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"✔️ Final balanced training DataFrame shuffled and index reset.\")\n",
        "\n",
        "# Display the head of the balanced_train_df_new and print its class distribution.\n",
        "print(\"\\nHead of the balanced_train_df_new:\")\n",
        "display(balanced_train_df_new.head())\n",
        "\n",
        "print(\"\\nClass distribution in balanced_train_df_new:\")\n",
        "print(balanced_train_df_new['label'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\n✔️ Data balancing using average target count complete.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructing the final balanced training DataFrame based on average target count...\n",
            "Target count for each class: 1333\n",
            "Processing class 'Cell' (label 0): original count 1502\n",
            "  Undersampled: Retained 1333 original samples.\n",
            "Processing class 'Cell-Multi' (label 1): original count 1030\n",
            "  Oversampling: Added 1030 original samples.\n",
            "  Oversampling: Generating 303 synthetic samples...\n",
            "  Oversampling: Generated 303 synthetic samples.\n",
            "Processing class 'Cracking' (label 2): original count 752\n",
            "  Oversampling: Added 752 original samples.\n",
            "  Oversampling: Generating 581 synthetic samples...\n",
            "  Oversampling: Generated 581 synthetic samples.\n",
            "Processing class 'Diode' (label 3): original count 1199\n",
            "  Oversampling: Added 1199 original samples.\n",
            "  Oversampling: Generating 134 synthetic samples...\n",
            "  Oversampling: Generated 134 synthetic samples.\n",
            "Processing class 'Diode-Multi' (label 4): original count 140\n",
            "  Oversampling: Added 140 original samples.\n",
            "  Oversampling: Generating 1193 synthetic samples...\n",
            "  Oversampling: Generated 1193 synthetic samples.\n",
            "Processing class 'Hot-Spot' (label 5): original count 199\n",
            "  Oversampling: Added 199 original samples.\n",
            "  Oversampling: Generating 1134 synthetic samples...\n",
            "  Oversampling: Generated 1134 synthetic samples.\n",
            "Processing class 'Hot-Spot-Multi' (label 6): original count 197\n",
            "  Oversampling: Added 197 original samples.\n",
            "  Oversampling: Generating 1136 synthetic samples...\n",
            "  Oversampling: Generated 1136 synthetic samples.\n",
            "Processing class 'No-Anomaly' (label 7): original count 8000\n",
            "  Undersampled: Retained 1333 original samples.\n",
            "Processing class 'Offline-Module' (label 8): original count 662\n",
            "  Oversampling: Added 662 original samples.\n",
            "  Oversampling: Generating 671 synthetic samples...\n",
            "  Oversampling: Generated 671 synthetic samples.\n",
            "Processing class 'Shadowing' (label 9): original count 845\n",
            "  Oversampling: Added 845 original samples.\n",
            "  Oversampling: Generating 488 synthetic samples...\n",
            "  Oversampling: Generated 488 synthetic samples.\n",
            "Processing class 'Soiling' (label 10): original count 163\n",
            "  Oversampling: Added 163 original samples.\n",
            "  Oversampling: Generating 1170 synthetic samples...\n",
            "  Oversampling: Generated 1170 synthetic samples.\n",
            "Processing class 'Vegetation' (label 11): original count 1311\n",
            "  Oversampling: Added 1311 original samples.\n",
            "  Oversampling: Generating 22 synthetic samples...\n",
            "  Oversampling: Generated 22 synthetic samples.\n",
            "✔️ Final balanced training DataFrame created.\n",
            "✔️ Final balanced training DataFrame shuffled and index reset.\n",
            "\n",
            "Head of the balanced_train_df_new:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   class_name  label                                               path\n",
              "0  Vegetation     11  /content/synthetic_images_final_balanced/synth...\n",
              "1    Hot-Spot      5  /content/synthetic_images_final_balanced/synth...\n",
              "2        Cell      0      /content/InfraredSolarModules/images/6189.jpg\n",
              "3  Cell-Multi      1      /content/InfraredSolarModules/images/4726.jpg\n",
              "4  Cell-Multi      1      /content/InfraredSolarModules/images/4274.jpg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7af2ced3-16ee-4ac9-9927-b5c5d88e14ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class_name</th>\n",
              "      <th>label</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vegetation</td>\n",
              "      <td>11</td>\n",
              "      <td>/content/synthetic_images_final_balanced/synth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hot-Spot</td>\n",
              "      <td>5</td>\n",
              "      <td>/content/synthetic_images_final_balanced/synth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cell</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/InfraredSolarModules/images/6189.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cell-Multi</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/InfraredSolarModules/images/4726.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cell-Multi</td>\n",
              "      <td>1</td>\n",
              "      <td>/content/InfraredSolarModules/images/4274.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7af2ced3-16ee-4ac9-9927-b5c5d88e14ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7af2ced3-16ee-4ac9-9927-b5c5d88e14ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7af2ced3-16ee-4ac9-9927-b5c5d88e14ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ad1faaee-1892-4013-9586-f863e94c025e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad1faaee-1892-4013-9586-f863e94c025e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ad1faaee-1892-4013-9586-f863e94c025e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2714\\ufe0f Data balancing using average target count complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hot-Spot\",\n          \"Cell-Multi\",\n          \"Vegetation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          1,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/synthetic_images_final_balanced/synthetic_final_Hot-Spot_955.png\",\n          \"/content/InfraredSolarModules/images/4274.jpg\",\n          \"/content/InfraredSolarModules/images/6189.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution in balanced_train_df_new:\n",
            "label\n",
            "0     1333\n",
            "1     1333\n",
            "2     1333\n",
            "3     1333\n",
            "4     1333\n",
            "5     1333\n",
            "6     1333\n",
            "7     1333\n",
            "8     1333\n",
            "9     1333\n",
            "10    1333\n",
            "11    1333\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✔️ Data balancing using average target count complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341ac293"
      },
      "source": [
        "**Reasoning**:\n",
        "The dataset (`balanced_train_df_new`) is now perfectly balanced with an equal number of samples per class. Therefore, a standard PyTorch DataLoader with shuffling is appropriate, and a `WeightedRandomSampler` is not needed. This step ensures the final DataLoader reflects the correctly balanced dataset for subsequent model training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80cd31b2",
        "outputId": "36bf68b7-44a4-47b7-86fb-1e58c0441e00"
      },
      "source": [
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "print(\"Creating a standard DataLoader for the final perfectly balanced training data (balanced_train_df_new)...\")\n",
        "\n",
        "# Ensure `transform` is available. It was defined in cell j3lovn9RFwOD and new_conditional_generator_definition.\n",
        "if 'transform' not in globals():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)), # Resize images to 64x64\n",
        "        transforms.ToTensor(),       # Convert PIL Image to PyTorch Tensor\n",
        "        transforms.Normalize(\n",
        "            mean=(0.5,),             # Normalize for 1-channel image (grayscale)\n",
        "            std=(0.5,)\n",
        "        )\n",
        "    ])\n",
        "    print(\"⚠️ `transform` pipeline not found, re-defined.\")\n",
        "else:\n",
        "    print(\"✔️ `transform` pipeline is already defined.\")\n",
        "\n",
        "# Ensure SolarDataset class is available (it was defined in cell j3lovn9RFwOD and new_conditional_generator_definition)\n",
        "if 'SolarDataset' not in globals():\n",
        "    class SolarDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, df, transform=None):\n",
        "            self.df = df.reset_index(drop=True)\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.df)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            row = self.df.iloc[idx]\n",
        "            image = Image.open(row[\"path\"]).convert(\"L\") # Open image and convert to grayscale\n",
        "            label = row[\"label\"]\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "    print(\"⚠️ `SolarDataset` class not found, re-defined.\")\n",
        "else:\n",
        "    print(\"✔️ `SolarDataset` class is already defined.\")\n",
        "\n",
        "# 1. Instantiate SolarDataset for the balanced training data using balanced_train_df_new\n",
        "balanced_train_dataset_final = SolarDataset(balanced_train_df_new, transform=transform)\n",
        "print(\"✔️ `balanced_train_dataset_final` created using `balanced_train_df_new`.\")\n",
        "\n",
        "# 2. Define batch size and number of workers\n",
        "# `batch_size` and `num_workers` are assumed to be defined from previous cells (e.g., j3lovn9RFwOD).\n",
        "# If not, default values will be used.\n",
        "if 'batch_size' not in globals():\n",
        "    batch_size = 32\n",
        "    print(f\"⚠️ `batch_size` not found, defaulting to {batch_size}.\")\n",
        "if 'num_workers' not in globals():\n",
        "    num_workers = 2\n",
        "    print(f\"⚠️ `num_workers` not found, defaulting to {num_workers}.\")\n",
        "\n",
        "# 3. Create a standard DataLoader with shuffle=True\n",
        "balanced_train_loader_final = torch.utils.data.DataLoader(\n",
        "    balanced_train_dataset_final,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,             # Shuffle the data as it's already balanced\n",
        "    num_workers=num_workers\n",
        ")\n",
        "print(\"✔️ Standard `balanced_train_loader_final` created with shuffling.\")\n",
        "\n",
        "# 4. Confirm that WeightedRandomSampler is not needed\n",
        "print(\"\\nConfirmation: A `WeightedRandomSampler` is NOT needed for `balanced_train_loader_final` because the `balanced_train_df_new` is now perfectly balanced, with each class containing an equal number of samples. Standard shuffling is sufficient for unbiased sampling.\")\n",
        "\n",
        "print(f\"Number of batches in balanced_train_loader_final: {len(balanced_train_loader_final)}\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a standard DataLoader for the final perfectly balanced training data (balanced_train_df_new)...\n",
            "✔️ `transform` pipeline is already defined.\n",
            "✔️ `SolarDataset` class is already defined.\n",
            "✔️ `balanced_train_dataset_final` created using `balanced_train_df_new`.\n",
            "✔️ Standard `balanced_train_loader_final` created with shuffling.\n",
            "\n",
            "Confirmation: A `WeightedRandomSampler` is NOT needed for `balanced_train_loader_final` because the `balanced_train_df_new` is now perfectly balanced, with each class containing an equal number of samples. Standard shuffling is sufficient for unbiased sampling.\n",
            "Number of batches in balanced_train_loader_final: 500\n"
          ]
        }
      ]
    }
  ]
}