{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FM11pp3/VC_0312/blob/main/Untitled0.ipynb)\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VC_0312 - Notebook arrumado\nNotebook dividido em: Configuracao -> Parte A (analise exploratoria + augmentations) -> Parte B (pesos pre-treinados para validar/testar) -> Anexos (treino + push GitHub)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como correr**\n- Ajusta `DATA_DIR` se nao estiveres em Colab.\n- Executa as celulas por ordem: Configuracao -> Parte A -> Parte B.\n- As celulas de Anexos sao opcionais para treino de raiz e push."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuracao"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed: int = SEED) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything()\n",
    "print(f\"Device: {DEVICE} | Seed: {SEED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Caminhos principais e dataset\n",
    "REPO_ROOT = Path(\".\").resolve()\n",
    "DATA_DIR = Path(\"/content/InfraredSolarModules\") if Path(\"/content\").exists() else REPO_ROOT / \"InfraredSolarModules\"\n",
    "DATA_URL = \"https://github.com/RaptorMaps/InfraredSolarModules/raw/master/2020-02-14_InfraredSolarModules.zip\"\n",
    "BASE_IMAGE_DIR = DATA_DIR / \"images\"\n",
    "MODELS_DIR = REPO_ROOT / \"models\"\n",
    "METRICS_DIR = REPO_ROOT / \"metrics\"\n",
    "TRAIN_CSV = REPO_ROOT / \"full_train_data_list.csv\"\n",
    "TEST_CSV = REPO_ROOT / \"final_test_data_list.csv\"\n",
    "\n",
    "def ensure_dataset() -> None:\n",
    "    \"\"\"Descarrega o dataset apenas se nao existir localmente.\"\"\"\n",
    "    if BASE_IMAGE_DIR.exists():\n",
    "        print(f\"?? Dataset pronto em {BASE_IMAGE_DIR}\")\n",
    "        return\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    zip_path = DATA_DIR.with_suffix(\".zip\")\n",
    "    print(\"?? A descarregar InfraredSolarModules (pode demorar)...\")\n",
    "    urllib.request.urlretrieve(DATA_URL, zip_path)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(DATA_DIR.parent)\n",
    "    print(f\"?? Dataset extraido para {DATA_DIR}\")\n",
    "\n",
    "def load_dataframes(image_dir: Path = BASE_IMAGE_DIR):\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    for df in (train_df, test_df):\n",
    "        df[\"filename\"] = df[\"path\"].apply(lambda p: Path(p).name)\n",
    "        df[\"path\"] = df[\"filename\"].apply(lambda n: image_dir / n)\n",
    "    class_pairs = train_df[[\"class_name\", \"label\"]].drop_duplicates().sort_values(\"label\")\n",
    "    classes_map = {row.class_name: int(row.label) for row in class_pairs.itertuples()}\n",
    "    idx_to_class = {v: k for k, v in classes_map.items()}\n",
    "    return train_df, test_df, classes_map, idx_to_class\n",
    "\n",
    "ensure_dataset()\n",
    "train_df, test_df, classes_map, idx_to_class = load_dataframes()\n",
    "print(f\"Train imgs: {len(train_df):,} | Test imgs: {len(test_df):,}\")\n",
    "display(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Analise exploratoria"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Distribuicao de classes (dataset original esta desbalanceado)\n",
    "order = train_df[\"class_name\"].value_counts().index\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.countplot(data=train_df, y=\"class_name\", order=order, palette=\"viridis\", ax=ax)\n",
    "ax.set_title(\"Distribuicao de classes (train)\")\n",
    "ax.bar_label(ax.containers[0], fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizar 1 imagem aleatoria + augmentations basicas\n",
    "sample = train_df.sample(1, random_state=SEED).iloc[0]\n",
    "img_path = Path(sample[\"path\"])\n",
    "if not img_path.exists():\n",
    "    raise FileNotFoundError(f\"Imagem nao encontrada: {img_path}. Confirma a celula de download do dataset.\")\n",
    "\n",
    "img = Image.open(img_path).convert(\"L\")\n",
    "augs = {\n",
    "    \"original\": lambda im: im,\n",
    "    \"flip_h\": lambda im: TF.hflip(im),\n",
    "    \"flip_v\": lambda im: TF.vflip(im),\n",
    "    \"rotate_20\": lambda im: TF.rotate(im, angle=20),\n",
    "    \"center_crop\": lambda im: TF.center_crop(im, output_size=(int(im.height * 0.8), int(im.width * 0.8))),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(augs), figsize=(15, 4))\n",
    "for ax, (name, fn) in zip(axes, augs.items()):\n",
    "    ax.imshow(fn(img), cmap=\"gray\")\n",
    "    ax.set_title(name)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(f\"Classe: {sample['class_name']} | ficheiro: {img_path.name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transforms padrao usados nos DataLoaders\n",
    "IMAGE_SIZE = (64, 64)\n",
    "train_transform = T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.Grayscale(),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomRotation(20),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.Grayscale(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "print(\"Transforms definidos (train/test).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Pesos pre-treinados: validar/testar"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Garantir que os pesos dos modelos estao disponiveis\n",
    "WEIGHT_URLS = {\n",
    "    \"model_A_final.pth\": \"https://raw.githubusercontent.com/FM11pp3/VC_0312/main/models/model_A_final.pth\",\n",
    "    \"model_B_final.pth\": \"https://raw.githubusercontent.com/FM11pp3/VC_0312/main/models/model_B_final.pth\",\n",
    "    \"model_C_final.pth\": \"https://raw.githubusercontent.com/FM11pp3/VC_0312/main/models/model_C_final.pth\",\n",
    "}\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def ensure_weights():\n",
    "    for fname, url in WEIGHT_URLS.items():\n",
    "        dest = MODELS_DIR / fname\n",
    "        if dest.exists():\n",
    "            print(f\"?? {fname} ja existe\")\n",
    "            continue\n",
    "        print(f\"?? A descarregar {fname}...\")\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "    print(\"Pronto.\")\n",
    "\n",
    "ensure_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dataset, modelo e helpers para avaliacao\n",
    "class SolarDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"path\"]).convert(\"L\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, int(row[\"label\"])\n",
    "\n",
    "def make_loader(df, transform, batch_size=256, shuffle=False):\n",
    "    return DataLoader(\n",
    "        SolarDataset(df, transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=2,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "class NetworkCNN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "        dummy_input = torch.randn(1, 1, 64, 64)\n",
    "        with torch.no_grad():\n",
    "            x = self.pool(F.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            flattened_size = torch.flatten(x, 1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def evaluate_model(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            preds = model(images).argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "    return correct / total if total else 0.0\n",
    "\n",
    "# Preparar dataframes para os 3 modelos\n",
    "anomaly_classes = sorted([c for c in classes_map if c != \"No-Anomaly\"])\n",
    "classes_map_B = {cls: idx for idx, cls in enumerate(anomaly_classes)}\n",
    "\n",
    "model_frames = {\n",
    "    \"A\": {\n",
    "        \"num_classes\": 2,\n",
    "        \"df\": test_df.assign(label=test_df[\"class_name\"].apply(lambda c: 0 if c == \"No-Anomaly\" else 1)),\n",
    "        \"weights\": MODELS_DIR / \"model_A_final.pth\",\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"num_classes\": len(anomaly_classes),\n",
    "        \"df\": test_df[test_df[\"class_name\"] != \"No-Anomaly\"].assign(label=lambda d: d[\"class_name\"].map(classes_map_B)),\n",
    "        \"weights\": MODELS_DIR / \"model_B_final.pth\",\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"num_classes\": len(classes_map),\n",
    "        \"df\": test_df.assign(label=lambda d: d[\"class_name\"].map(classes_map)),\n",
    "        \"weights\": MODELS_DIR / \"model_C_final.pth\",\n",
    "    },\n",
    "}\n",
    "\n",
    "results = []\n",
    "for key, cfg in model_frames.items():\n",
    "    loader = make_loader(cfg[\"df\"], test_transform, batch_size=256)\n",
    "    model = NetworkCNN(cfg[\"num_classes\"]).to(DEVICE)\n",
    "    state = torch.load(cfg[\"weights\"], map_location=DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    acc = evaluate_model(model, loader)\n",
    "    results.append({\"Model\": f\"Model {key}\", \"test_accuracy\": acc})\n",
    "    print(f\"Model {key}: test accuracy = {acc:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "metrics_path = METRICS_DIR / \"final_test_metrics.csv\"\n",
    "if metrics_path.exists():\n",
    "    print(\"Metricas exportadas no treino original:\")\n",
    "    display(pd.read_csv(metrics_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anexos - Treino de raiz e push para GitHub"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Treino rapido (exemplo) ? usa o modelo C (12 classes) como base\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(model_name: str, base_df: pd.DataFrame, num_classes: int, epochs: int = 3, lr: float = 1e-3):\n",
    "    train_split, val_split = train_test_split(base_df, test_size=0.2, stratify=base_df[\"label\"], random_state=SEED)\n",
    "    train_loader = make_loader(train_split, train_transform, batch_size=128, shuffle=True)\n",
    "    val_loader = make_loader(val_split, test_transform, batch_size=256)\n",
    "\n",
    "    model = NetworkCNN(num_classes).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} | loss={running_loss / len(train_loader.dataset):.4f} | val_acc={val_acc:.3f}\")\n",
    "\n",
    "    out_path = MODELS_DIR / f\"{model_name}.pth\"\n",
    "    torch.save(model.state_dict(), out_path)\n",
    "    print(f\"Modelo guardado em {out_path}\")\n",
    "    return model\n",
    "\n",
    "# Exemplo (comenta se nao quiseres treinar no notebook):\n",
    "# trained_model = train_model(\"model_C_scratch\", test_df.assign(label=lambda d: d[\"class_name\"].map(classes_map)), num_classes=len(classes_map), epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Push rapido dos artefactos (usa HTTPS). Configura antes: git config user.email/name e token de acesso se precisa.\n",
    "# Descomenta as linhas abaixo quando estiveres autenticado.\n",
    "# !git status\n",
    "# !git add models/*.pth metrics/*.csv\n",
    "# !git commit -m \"Add modelos e metricas atualizadas\"\n",
    "# !git push origin main\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}